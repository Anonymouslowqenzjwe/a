{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ff5dfe-b3d0-4ee2-aad9-98090ae02444",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CodeQwuen LLMs with LoRA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6f617-7416-41e7-9974-42167c31392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    "    balanced_accuracy_score, precision_score, recall_score, jaccard_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, roc_auc_score, average_precision_score,\n",
    "    log_loss, brier_score_loss\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "class LoRATrainer:\n",
    "    def __init__(self, train_file, test_file, func1_col, func2_col, label_col, cache_dir=None):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.func1_col = func1_col\n",
    "        self.func2_col = func2_col\n",
    "        self.label_col = label_col\n",
    "        self.cache_dir = cache_dir\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        logger.info(f\"Number of available GPUs: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            logger.info(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "        logger.info(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\", \n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        logger.info(\"Loading base model with automatic device mapping...\")\n",
    "        self.base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        logger.info(\"Loading datasets...\")\n",
    "        self.train_data = HFDataset.from_csv(train_file)\n",
    "        self.test_data = HFDataset.from_csv(test_file)\n",
    "        logger.info(f\"Train samples: {len(self.train_data)}\")\n",
    "        logger.info(f\"Test samples: {len(self.test_data)}\")\n",
    "        \n",
    "        self.training_stats = {\n",
    "            'epoch_times': [],\n",
    "            'epoch_losses': [],\n",
    "            'memory_usage': []\n",
    "        }\n",
    "    \n",
    "    def print_model_distribution(self):\n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"MODEL DEVICE DISTRIBUTION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        if hasattr(self.base_model, 'hf_device_map'):\n",
    "            device_map = self.base_model.hf_device_map\n",
    "            for module_name, device in device_map.items():\n",
    "                logger.info(f\"{module_name}: {device}\")\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"GPU MEMORY USAGE\")\n",
    "        logger.info(\"=\"*80)\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            logger.info(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "        logger.info(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "    def preprocess(self, batch):\n",
    "        c1 = batch[self.func1_col]\n",
    "        c2 = batch[self.func2_col]\n",
    "        y = batch[self.label_col]\n",
    "        text = f\"<func1>\\n{c1}\\n</func1>\\n<func2>\\n{c2}\\n</func2>\\nLabel: {y}\"\n",
    "        out = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "        out[\"labels\"] = out[\"input_ids\"]\n",
    "        return out\n",
    "    \n",
    "    def count_parameters(self, model):\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        return total_params, trainable_params\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred, y_prob=None):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "        \n",
    "        jacc = jaccard_score(y_true, y_pred, zero_division=0)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "        \n",
    "        metrics = {\n",
    "            'cm': cm,\n",
    "            'acc': acc,\n",
    "            'bal_acc': bal_acc,\n",
    "            'prec': prec,\n",
    "            'rec': rec,\n",
    "            'f1': f1,\n",
    "            'jacc': jacc,\n",
    "            'mcc': mcc,\n",
    "            'kappa': kappa,\n",
    "            'specificity': specificity,\n",
    "            'npv': npv,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr\n",
    "        }\n",
    "        \n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(y_true, y_prob)\n",
    "                pr_auc = average_precision_score(y_true, y_prob)\n",
    "                ll = log_loss(y_true, y_prob)\n",
    "                brier = brier_score_loss(y_true, y_prob)\n",
    "                \n",
    "                metrics.update({\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'log_loss': ll,\n",
    "                    'brier': brier\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def calculate_recall_at_k(self, embeddings, labels, k_values=[1, 3, 5, 10]):\n",
    "        results = {}\n",
    "        \n",
    "        similarity_matrix = torch.nn.functional.cosine_similarity(\n",
    "            embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2\n",
    "        )\n",
    "        \n",
    "        for k in k_values:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                query_label = labels[i]\n",
    "                similarities = similarity_matrix[i]\n",
    "                similarities[i] = -float('inf')\n",
    "                \n",
    "                top_k_indices = torch.topk(similarities, k).indices\n",
    "                top_k_labels = [labels[idx] for idx in top_k_indices]\n",
    "                \n",
    "                if query_label in top_k_labels:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "        \n",
    "        reciprocal_ranks = []\n",
    "        for i in range(len(labels)):\n",
    "            query_label = labels[i]\n",
    "            similarities = similarity_matrix[i]\n",
    "            similarities[i] = -float('inf')\n",
    "            \n",
    "            sorted_indices = torch.argsort(similarities, descending=True)\n",
    "            sorted_labels = [labels[idx] for idx in sorted_indices]\n",
    "            \n",
    "            try:\n",
    "                rank = sorted_labels.index(query_label) + 1\n",
    "                reciprocal_ranks.append(1.0 / rank)\n",
    "            except ValueError:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "        \n",
    "        results['mrr'] = np.mean(reciprocal_ranks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def train(self):\n",
    "        train_dataset = self.train_data.map(self.preprocess, batched=False)\n",
    "        test_dataset = self.test_data.map(self.preprocess, batched=False)\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"APPLYING LORA CONFIGURATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        peft_config = LoraConfig(\n",
    "            r=8,\n",
    "            lora_alpha=16,\n",
    "            lora_dropout=0.0,\n",
    "            target_modules=[\"q_proj\", \"v_proj\"],\n",
    "            task_type=TaskType.CAUSAL_LM\n",
    "        )\n",
    "        \n",
    "        model = get_peft_model(self.base_model, peft_config)\n",
    "        \n",
    "        total_params, trainable_params = self.count_parameters(model)\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"PARAMETER STATISTICS\")\n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(f\"Total parameters: {total_params:,}\")\n",
    "        logger.info(f\"Trainable parameters: {trainable_params:,}\")\n",
    "        logger.info(f\"Trainable percentage: {100 * trainable_params / total_params:.4f}%\")\n",
    "        logger.info(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"codeqwen1.5-clone-lora\",\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=4,\n",
    "            gradient_accumulation_steps=4,\n",
    "            num_train_epochs=5,\n",
    "            learning_rate=2e-4,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            warmup_ratio=0.03,\n",
    "            logging_steps=20,\n",
    "            save_total_limit=2,\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            fp16=True,\n",
    "            bf16=False,\n",
    "            dataloader_num_workers=0,\n",
    "            dataloader_pin_memory=True,\n",
    "            gradient_checkpointing=False,\n",
    "            optim=\"adamw_torch\"\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset\n",
    "        )\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING TRAINING\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        training_start = time.time()\n",
    "        \n",
    "        process = psutil.Process(os.getpid())\n",
    "        mem_before = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        train_result = trainer.train()\n",
    "        \n",
    "        total_training_time = time.time() - training_start\n",
    "        \n",
    "        mem_after = process.memory_info().rss / 1024 / 1024\n",
    "        mem_used = mem_after - mem_before\n",
    "        \n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"TRAINING COMPLETE\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "        logger.info(f\"Memory Usage: {mem_used:.1f} MB\")\n",
    "        logger.info(f\"{'='*80}\\n\")\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        model.save_pretrained(\"codeqwen1.5-lora-clone\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return model, trainer, total_training_time\n",
    "    \n",
    "    def evaluate_comprehensive(self, model, test_dataset):\n",
    "        model.eval()\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING COMPREHENSIVE EVALUATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        test_df = pd.read_csv(self.test_file)\n",
    "        test_labels = test_df[self.label_col].tolist()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_embeddings = []\n",
    "        \n",
    "        inference_start = time.time()\n",
    "        total_samples = len(test_dataset)\n",
    "        \n",
    "        logger.info(f\"Processing {total_samples} test samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx in range(len(test_dataset)):\n",
    "                sample = test_dataset[idx]\n",
    "                \n",
    "                input_ids = torch.tensor([sample['input_ids']])\n",
    "                attention_mask = torch.tensor([sample['attention_mask']])\n",
    "                \n",
    "                first_device = next(model.parameters()).device\n",
    "                input_ids = input_ids.to(first_device)\n",
    "                attention_mask = attention_mask.to(first_device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    output_hidden_states=True\n",
    "                )\n",
    "                \n",
    "                hidden_states = outputs.hidden_states[-1]\n",
    "                pooled = hidden_states.mean(dim=1)\n",
    "                \n",
    "                logits = pooled.squeeze()\n",
    "                all_embeddings.append(logits.cpu())\n",
    "                \n",
    "                pred = 1 if logits.mean().item() > 0 else 0\n",
    "                prob = torch.sigmoid(logits.mean()).item()\n",
    "                \n",
    "                all_preds.append(pred)\n",
    "                all_probs.append(prob)\n",
    "                \n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    logger.info(f\"Processed {idx + 1}/{total_samples} samples\")\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        inference_time = time.time() - inference_start\n",
    "        samples_per_sec = total_samples / inference_time\n",
    "        \n",
    "        logger.info(f\"Inference completed in {inference_time:.2f}s\")\n",
    "        logger.info(f\"Throughput: {samples_per_sec:.2f} samples/sec\")\n",
    "        \n",
    "        metrics = self.calculate_metrics(test_labels, all_preds, all_probs)\n",
    "        \n",
    "        all_embeddings = torch.stack(all_embeddings)\n",
    "        recall_metrics = self.calculate_recall_at_k(all_embeddings, test_labels)\n",
    "        metrics.update(recall_metrics)\n",
    "        \n",
    "        metrics['inference_time'] = inference_time\n",
    "        metrics['samples_per_sec'] = samples_per_sec\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def print_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['cm']}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall: {metrics['rec']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"Jaccard: {metrics['jacc']:.4f}\")\n",
    "    print(f\"MCC: {metrics['mcc']:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"NPV: {metrics['npv']:.4f}\")\n",
    "    print(f\"FPR: {metrics['fpr']:.4f}\")\n",
    "    print(f\"FNR: {metrics['fnr']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    if 'pr_auc' in metrics:\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "    if 'log_loss' in metrics:\n",
    "        print(f\"Log Loss: {metrics['log_loss']:.4f}\")\n",
    "    if 'brier' in metrics:\n",
    "        print(f\"Brier Score: {metrics['brier']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"\\nRetrieval Metrics:\")\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@3: {metrics['recall@3']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"MRR: {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    if 'inference_time' in metrics:\n",
    "        print(f\"\\nPerformance:\")\n",
    "        print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "        print(f\"Samples/sec: {metrics['samples_per_sec']:.0f}\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def run_lora_experiment(train_file, test_file, func1_col, func2_col, label_col, cache_dir=None):\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"CODE CLONE DETECTION WITH LORA\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    lora_trainer = LoRATrainer(\n",
    "        train_file, \n",
    "        test_file, \n",
    "        func1_col, \n",
    "        func2_col, \n",
    "        label_col,\n",
    "        cache_dir=cache_dir\n",
    "    )\n",
    "    \n",
    "    model, trainer, training_time = lora_trainer.train()\n",
    "    \n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"FINAL TEST EVALUATION\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    test_dataset = lora_trainer.test_data.map(lora_trainer.preprocess, batched=False)\n",
    "    metrics = lora_trainer.evaluate_comprehensive(model, test_dataset)\n",
    "    \n",
    "    print_results(metrics, \"TEST SET\")\n",
    "    \n",
    "    return lora_trainer, model, metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_file = 'train.csv'\n",
    "    test_file = '/test.csv'\n",
    "    func1_col = \"func1\"\n",
    "    func2_col = \"func2\"\n",
    "    label_col = \"label\"\n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    try:\n",
    "        lora_trainer, model, results = run_lora_experiment(\n",
    "            train_file, \n",
    "            test_file, \n",
    "            func1_col, \n",
    "            func2_col, \n",
    "            label_col,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "        logger.info(\"LoRA experiment completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0de5b-7177-4415-946c-a4fc923bda99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# adpater tuning with CodeQueen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a60b7-cd31-4cee-8e17-80445b1a53e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, balanced_accuracy_score, \n",
    "    matthews_corrcoef, roc_auc_score, average_precision_score, f1_score\n",
    ")\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class Activation_Function_Class(nn.Module):\n",
    "    def __init__(self, hidden_act):\n",
    "        super().__init__()\n",
    "        if hidden_act.lower() == \"relu\":\n",
    "            self.f = nn.functional.relu\n",
    "        elif hidden_act.lower() == \"tanh\":\n",
    "            self.f = torch.tanh\n",
    "        elif hidden_act.lower() == \"swish\":\n",
    "            def swish(x):\n",
    "                return x * torch.sigmoid(x)\n",
    "            self.f = swish\n",
    "        elif hidden_act.lower() == \"gelu\":\n",
    "            def gelu_new(x):\n",
    "                return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "            self.f = gelu_new\n",
    "        elif hidden_act.lower() == \"leakyrelu\":\n",
    "            self.f = nn.functional.leaky_relu\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)\n",
    "\n",
    "\n",
    "class Adapter(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size,\n",
    "            down_sample=None,\n",
    "            non_linearity=\"relu\",\n",
    "            init_bert_weights=True,\n",
    "            add_layer_norm_before=True,\n",
    "            residual_before_ln=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.add_layer_norm_before = add_layer_norm_before\n",
    "        self.residual_before_ln = residual_before_ln\n",
    "        \n",
    "        seq_list = []\n",
    "        \n",
    "        if self.add_layer_norm_before:\n",
    "            self.adapter_norm_before = nn.LayerNorm(self.input_size)\n",
    "            seq_list.append(self.adapter_norm_before)\n",
    "        \n",
    "        self.down_sample = down_sample\n",
    "        if down_sample is None:\n",
    "            self.down_sample = self.input_size // 2\n",
    "        \n",
    "        seq_list.append(nn.Linear(self.input_size, self.down_sample))\n",
    "        \n",
    "        self.non_linearity = Activation_Function_Class(non_linearity.lower())\n",
    "        seq_list.append(self.non_linearity)\n",
    "        \n",
    "        self.adapter_down = nn.Sequential(*seq_list)\n",
    "        self.adapter_up = nn.Linear(self.down_sample, self.input_size)\n",
    "        \n",
    "        if init_bert_weights:\n",
    "            self.adapter_down.apply(self.init_bert_weights)\n",
    "            self.adapter_up.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_dtype = x.dtype\n",
    "        down = self.adapter_down(x)\n",
    "        up = self.adapter_up(down)\n",
    "        output = up\n",
    "        output = output + x\n",
    "        return output.to(input_dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_bert_weights(module):\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "\n",
    "class CodeCloneDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class AdapterTuningCodeQwen(nn.Module):\n",
    "    def __init__(self, model_name: str, adapter_size: int = 512, num_classes: int = 2, cache_dir: str = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Initializing model across {num_gpus} GPUs\")\n",
    "        \n",
    "        self.primary_device = 'cuda:0'\n",
    "        \n",
    "        print(\"Loading base LLM model...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            cache_dir=cache_dir,\n",
    "            low_cpu_mem_usage=True,\n",
    "            device_map='auto'\n",
    "        )\n",
    "        \n",
    "        self.llm = base_model\n",
    "        \n",
    "        total_layers = len(base_model.model.layers)\n",
    "        print(f\"Model has {total_layers} transformer layers\")\n",
    "        \n",
    "        self.layer_devices = []\n",
    "        for i in range(total_layers):\n",
    "            layer_device = next(base_model.model.layers[i].parameters()).device\n",
    "            self.layer_devices.append(str(layer_device))\n",
    "            if i % 5 == 0:\n",
    "                print(f\"  Layer {i} -> {layer_device}\")\n",
    "        \n",
    "        embed_device = next(base_model.model.embed_tokens.parameters()).device\n",
    "        norm_device = next(base_model.model.norm.parameters()).device\n",
    "        lm_head_device = next(base_model.lm_head.parameters()).device\n",
    "        \n",
    "        print(f\"Embeddings -> {embed_device}\")\n",
    "        print(f\"Norm -> {norm_device}\")\n",
    "        print(f\"LM Head -> {lm_head_device}\")\n",
    "        \n",
    "        self.embed_device = str(embed_device)\n",
    "        self.final_device = str(norm_device)\n",
    "        \n",
    "        self.hidden_size = base_model.config.hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.adapters = nn.ModuleList([\n",
    "            Adapter(\n",
    "                input_size=self.hidden_size,\n",
    "                down_sample=adapter_size,\n",
    "                non_linearity=\"gelu\",\n",
    "                init_bert_weights=True,\n",
    "                add_layer_norm_before=True\n",
    "            ) for _ in range(total_layers)\n",
    "        ])\n",
    "        \n",
    "        for i, adapter in enumerate(self.adapters):\n",
    "            adapter.to(self.layer_devices[i]).half()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.hidden_size // 4, num_classes)\n",
    "        ).to(self.primary_device)\n",
    "        \n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data = module.weight.data.half()\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data = module.bias.data.half()\n",
    "        \n",
    "        for param in self.llm.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for adapter in self.adapters:\n",
    "            for param in adapter.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        print(\"Model initialization complete!\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        input_ids = input_ids.to(self.embed_device)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.to(self.embed_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.llm(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True\n",
    "            )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "        for i, adapter in enumerate(self.adapters):\n",
    "            if i < len(self.adapters) - 1:\n",
    "                continue\n",
    "            else:\n",
    "                adapter_device = self.layer_devices[i]\n",
    "                hidden_states = hidden_states.to(adapter_device)\n",
    "                hidden_states = adapter(hidden_states)\n",
    "        \n",
    "        if str(hidden_states.device) != self.primary_device:\n",
    "            hidden_states = hidden_states.to(self.primary_device)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attention_mask_expanded = attention_mask.to(self.primary_device).unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "            attention_mask_expanded = attention_mask_expanded.half()\n",
    "            sum_embeddings = torch.sum(hidden_states * attention_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)\n",
    "            pooled_output = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            pooled_output = hidden_states.mean(dim=1)\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if labels.device != logits.device:\n",
    "                labels = labels.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return {'logits': logits, 'loss': loss, 'hidden_states': hidden_states}\n",
    "\n",
    "\n",
    "def print_parameter_statistics(model: AdapterTuningCodeQwen):\n",
    "    total_params = sum(p.numel() for p in model.llm.parameters())\n",
    "    adapter_params = sum(p.numel() for p in model.adapters.parameters())\n",
    "    classifier_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "    trainable_params = adapter_params + classifier_params\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PARAMETER STATISTICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Frozen LLM Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Adapter Parameters: {adapter_params:,}\")\n",
    "    print(f\"Trainable Classifier Parameters: {classifier_params:,}\")\n",
    "    print(f\"Total Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable Ratio: {(trainable_params / total_params * 100):.4f}%\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"GPU MEMORY USAGE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "        print(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def load_dataset(csv_path, label_col, func1_col, func2_col):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded dataset: {len(df)} samples\")\n",
    "        print(f\"Label distribution: {df[label_col].value_counts().to_dict()}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_training_data(csv_path, tokenizer, max_length=512, \n",
    "                        label_col='label', func1_col='func1', func2_col='func2'):\n",
    "    df = load_dataset(csv_path, label_col, func1_col, func2_col)\n",
    "    \n",
    "    if df is None:\n",
    "        return []\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        func1 = str(row[func1_col])\n",
    "        func2 = str(row[func2_col])\n",
    "        label = int(row[label_col])\n",
    "        \n",
    "        combined_text = f\"Code1: {func1}\\nCode2: {func2}\\nAre these code clones?\"\n",
    "        \n",
    "        encoding = tokenizer(\n",
    "            combined_text,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        train_data.append({\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        })\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "\n",
    "def calculate_recall_at_k(embeddings, labels, k_values=[1, 5, 10]):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            true_label = labels[i]\n",
    "            sims = similarities[i].clone()\n",
    "            sims[i] = -float('inf')\n",
    "            \n",
    "            top_k_indices = torch.topk(sims, min(k, len(labels)-1)).indices\n",
    "            top_k_labels = labels[top_k_indices]\n",
    "            \n",
    "            if true_label in top_k_labels:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_mrr(embeddings, labels):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    mrr_sum = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        sims = similarities[i].clone()\n",
    "        sims[i] = -float('inf')\n",
    "        \n",
    "        sorted_indices = torch.argsort(sims, descending=True)\n",
    "        sorted_labels = labels[sorted_indices]\n",
    "        \n",
    "        for rank, label in enumerate(sorted_labels, 1):\n",
    "            if label == true_label:\n",
    "                mrr_sum += 1.0 / rank\n",
    "                break\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return mrr_sum / count if count > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, y_proba=None, embeddings=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    if cm.shape != (2, 2):\n",
    "        cm_2x2 = np.zeros((2, 2))\n",
    "        for i in range(min(cm.shape[0], 2)):\n",
    "            for j in range(min(cm.shape[1], 2)):\n",
    "                cm_2x2[i, j] = cm[i, j]\n",
    "        cm = cm_2x2\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    \n",
    "    if y_proba is not None and len(np.unique(y_true)) > 1:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_proba)\n",
    "            pr_auc = average_precision_score(y_true, y_proba)\n",
    "        except:\n",
    "            roc_auc = pr_auc = 0.0\n",
    "    else:\n",
    "        roc_auc = pr_auc = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'cm': cm,\n",
    "        'acc': acc,\n",
    "        'bal_acc': bal_acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'specificity': specificity,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "    \n",
    "    if embeddings is not None:\n",
    "        recall_metrics = calculate_recall_at_k(embeddings, torch.tensor(y_true))\n",
    "        mrr = calculate_mrr(embeddings, torch.tensor(y_true))\n",
    "        results.update(recall_metrics)\n",
    "        results['mrr'] = mrr\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "\n",
    "def train_model(model, train_data, num_epochs=5, learning_rate=1e-4, batch_size=2):\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': model.adapters.parameters()},\n",
    "        {'params': model.classifier.parameters()}\n",
    "    ], lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    dataset = CodeCloneDataset(train_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_stats = []\n",
    "    start_time = time.time()\n",
    "    initial_memory = get_memory_usage()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batch_count = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            total_tokens += input_ids.numel()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                \n",
    "                adapter_params = []\n",
    "                for adapter in model.adapters:\n",
    "                    adapter_params.extend(list(adapter.parameters()))\n",
    "                classifier_params = list(model.classifier.parameters())\n",
    "                all_params = adapter_params + classifier_params\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(all_params, 1.0)\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                    correct += (predictions == labels.to(predictions.device)).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            \n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        tokens_per_sec = total_tokens / epoch_time\n",
    "        current_memory = get_memory_usage()\n",
    "        \n",
    "        epoch_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': avg_loss,\n",
    "            'acc': accuracy,\n",
    "            'time': epoch_time,\n",
    "            'tokens_per_sec': tokens_per_sec,\n",
    "            'memory_mb': current_memory\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}, \"\n",
    "              f\"Time: {epoch_time:.2f}s, Tokens/sec: {tokens_per_sec:.2f}, Memory: {current_memory:.2f}MB\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            print(f\"  GPU {i} Memory: {allocated:.2f} GB\")\n",
    "    \n",
    "    total_training_time = time.time() - start_time\n",
    "    peak_memory = max([stat['memory_mb'] for stat in epoch_stats])\n",
    "    memory_increase = peak_memory - initial_memory\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "    print(f\"Peak Memory Usage: {peak_memory:.2f}MB\")\n",
    "    print(f\"Memory Increase: {memory_increase:.2f}MB\")\n",
    "    print(f\"Average Tokens/sec: {np.mean([s['tokens_per_sec'] for s in epoch_stats]):.2f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return epoch_stats\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, batch_size=2):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    all_embeddings = []\n",
    "    \n",
    "    dataset = CodeCloneDataset(test_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            total_tokens += input_ids.numel()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            hidden_states = outputs['hidden_states']\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            pooled_embeddings = hidden_states.mean(dim=1)\n",
    "            pooled_embeddings = F.normalize(pooled_embeddings, p=2, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())\n",
    "            all_embeddings.append(pooled_embeddings.cpu())\n",
    "            \n",
    "            if len(all_predictions) % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    tokens_per_sec = total_tokens / inference_time\n",
    "    \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    metrics = calculate_comprehensive_metrics(\n",
    "        all_labels, \n",
    "        all_predictions, \n",
    "        all_probabilities,\n",
    "        all_embeddings\n",
    "    )\n",
    "    \n",
    "    metrics['inference_time'] = inference_time\n",
    "    metrics['tokens_per_sec'] = tokens_per_sec\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_evaluation_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EVALUATION RESULTS - {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['cm']}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall: {metrics['rec']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"MCC: {metrics['mcc']:.4f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"MRR: {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "    print(f\"Tokens/sec: {metrics['tokens_per_sec']:.2f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    primary_device = 'cuda:0'\n",
    "    \n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/CodeQwen1.5-7B-Chat\", cache_dir=cache_dir)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    print(\"\\nLoading model with adapter tuning and pipeline parallelism across GPUs...\")\n",
    "    model = AdapterTuningCodeQwen(\"Qwen/CodeQwen1.5-7B-Chat\", adapter_size=512, num_classes=2, cache_dir=cache_dir)\n",
    "    print_parameter_statistics(model)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    train_csv = 'train.csv'\n",
    "    train_data = create_training_data(\n",
    "        train_csv, \n",
    "        tokenizer,\n",
    "        label_col='label', \n",
    "        func1_col='func1', \n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(train_data)} training examples\\n\")\n",
    "    \n",
    "    if len(train_data) == 0:\n",
    "        print(\"No training data available. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    epoch_stats = train_model(model, train_data, num_epochs=5, learning_rate=1e-4, batch_size=2)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TESTING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    test_csv = 'test.csv'\n",
    "    test_data = create_training_data(\n",
    "        test_csv,\n",
    "        tokenizer,\n",
    "        label_col='label',\n",
    "        func1_col='func1',\n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(test_data)} test examples\\n\")\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        test_metrics = evaluate_model(model, test_data, batch_size=2)\n",
    "        print_evaluation_results(test_metrics, \"TEST SET\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a19b2-713f-4359-a52c-65ef1b943299",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# bitFit codeQwueen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556434c-42cd-4236-97da-897a342ea819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    "    balanced_accuracy_score, precision_score, recall_score, jaccard_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, roc_auc_score, average_precision_score,\n",
    "    log_loss, brier_score_loss\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "class BitFitClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels=1, dtype=torch.float16):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size, dtype=dtype)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(hidden_size, num_labels, dtype=dtype)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        x = self.dropout(hidden_states)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BitFitCloneTrainer:\n",
    "    BIAS_TERMS_MAPPING = {\n",
    "        'query': 'q_proj.bias',\n",
    "        'key': 'k_proj.bias',\n",
    "        'value': 'v_proj.bias',\n",
    "        'output': 'o_proj.bias',\n",
    "        'mlp': 'mlp',\n",
    "        'layer_norm': 'ln',\n",
    "        'all': 'bias'\n",
    "    }\n",
    "\n",
    "    def __init__(self, train_file, test_file, func1_col, func2_col, label_col, cache_dir=None, bias_terms=['all']):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.func1_col = func1_col\n",
    "        self.func2_col = func2_col\n",
    "        self.label_col = label_col\n",
    "        self.cache_dir = cache_dir\n",
    "        self.bias_terms = bias_terms\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        logger.info(f\"Number of available GPUs: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            logger.info(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "        logger.info(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\", \n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        logger.info(\"Loading base model with automatic device mapping...\")\n",
    "        self.base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.base_model.config.hidden_size\n",
    "        logger.info(f\"Model hidden size: {hidden_size}\")\n",
    "        \n",
    "        self.classification_head = None\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        logger.info(\"Loading datasets...\")\n",
    "        self.train_data = HFDataset.from_csv(train_file)\n",
    "        self.test_data = HFDataset.from_csv(test_file)\n",
    "        logger.info(f\"Train samples: {len(self.train_data)}\")\n",
    "        logger.info(f\"Test samples: {len(self.test_data)}\")\n",
    "        \n",
    "        self.training_stats = {\n",
    "            'epoch_times': [],\n",
    "            'epoch_losses': [],\n",
    "            'memory_usage': []\n",
    "        }\n",
    "        \n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "    \n",
    "    def print_model_distribution(self):\n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"MODEL DEVICE DISTRIBUTION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        if hasattr(self.base_model, 'hf_device_map'):\n",
    "            device_map = self.base_model.hf_device_map\n",
    "            for module_name, device in device_map.items():\n",
    "                logger.info(f\"{module_name}: {device}\")\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"GPU MEMORY USAGE\")\n",
    "        logger.info(\"=\"*80)\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            logger.info(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "        logger.info(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    def preprocess(self, example):\n",
    "        c1 = example[self.func1_col]\n",
    "        c2 = example[self.func2_col]\n",
    "        y = example[self.label_col]\n",
    "        text = f\"<func1>\\n{c1}\\n</func1>\\n<func2>\\n{c2}\\n</func2>\"\n",
    "        out = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "        out[\"labels\"] = y\n",
    "        return out\n",
    "    \n",
    "    def _setup_bitfit_parameters(self):\n",
    "        logger.info(\"Setting up BitFit parameters...\")\n",
    "        \n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        trainable_bias_terms = self._get_trainable_bias_terms()\n",
    "        \n",
    "        trainable_params = 0\n",
    "        total_params = 0\n",
    "        bias_param_count = 0\n",
    "        \n",
    "        for name, param in self.base_model.named_parameters():\n",
    "            total_params += param.numel()\n",
    "            \n",
    "            should_train = False\n",
    "            for bias_term in trainable_bias_terms:\n",
    "                if bias_term in name and 'bias' in name:\n",
    "                    should_train = True\n",
    "                    break\n",
    "            \n",
    "            if should_train:\n",
    "                param.requires_grad = True\n",
    "                trainable_params += param.numel()\n",
    "                bias_param_count += param.numel()\n",
    "                logger.info(f\" Trainable: {name} - Shape: {param.shape} - Params: {param.numel():,}\")\n",
    "        \n",
    "        hidden_size = self.base_model.config.hidden_size\n",
    "        first_device = next(self.base_model.parameters()).device\n",
    "        model_dtype = next(self.base_model.parameters()).dtype\n",
    "        \n",
    "        self.classification_head = BitFitClassificationHead(hidden_size, num_labels=1, dtype=model_dtype)\n",
    "        self.classification_head = self.classification_head.to(first_device)\n",
    "        \n",
    "        head_params = sum(p.numel() for p in self.classification_head.parameters())\n",
    "        trainable_params += head_params\n",
    "        total_params += head_params\n",
    "        \n",
    "        logger.info(f\"\\n Classification Head added: {head_params:,} parameters\")\n",
    "        for name, param in self.classification_head.named_parameters():\n",
    "            logger.info(f\"   {name} - Shape: {param.shape} - Params: {param.numel():,}\")\n",
    "        \n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"BITFIT PARAMETER STATISTICS\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"Base Model Total Parameters: {total_params - head_params:,}\")\n",
    "        logger.info(f\"Trainable Bias Parameters: {bias_param_count:,}\")\n",
    "        logger.info(f\"Classification Head Parameters: {head_params:,}\")\n",
    "        logger.info(f\"Total Trainable Parameters: {trainable_params:,}\")\n",
    "        logger.info(f\"Total Parameters: {total_params:,}\")\n",
    "        logger.info(f\"Trainable Percentage: {100 * trainable_params / total_params:.6f}%\")\n",
    "        logger.info(f\"{'='*80}\\n\")\n",
    "    \n",
    "    def _get_trainable_bias_terms(self) -> List[str]:\n",
    "        trainable_terms = []\n",
    "        \n",
    "        for term in self.bias_terms:\n",
    "            if term in self.BIAS_TERMS_MAPPING:\n",
    "                trainable_terms.append(self.BIAS_TERMS_MAPPING[term])\n",
    "            else:\n",
    "                logger.warning(f\"Unknown bias term: {term}\")\n",
    "        \n",
    "        return trainable_terms\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred, y_prob=None):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "        \n",
    "        jacc = jaccard_score(y_true, y_pred, zero_division=0)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "        \n",
    "        metrics = {\n",
    "            'cm': cm,\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp),\n",
    "            'acc': acc,\n",
    "            'bal_acc': bal_acc,\n",
    "            'prec': prec,\n",
    "            'rec': rec,\n",
    "            'f1': f1,\n",
    "            'jacc': jacc,\n",
    "            'mcc': mcc,\n",
    "            'kappa': kappa,\n",
    "            'specificity': specificity,\n",
    "            'npv': npv,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr\n",
    "        }\n",
    "        \n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(y_true, y_prob)\n",
    "                pr_auc = average_precision_score(y_true, y_prob)\n",
    "                ll = log_loss(y_true, y_prob)\n",
    "                brier = brier_score_loss(y_true, y_prob)\n",
    "                \n",
    "                metrics.update({\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'log_loss': ll,\n",
    "                    'brier': brier\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not calculate probabilistic metrics: {e}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def calculate_recall_at_k(self, embeddings, labels, k_values=[1, 3, 5, 10]):\n",
    "        results = {}\n",
    "        \n",
    "        similarity_matrix = torch.nn.functional.cosine_similarity(\n",
    "            embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2\n",
    "        )\n",
    "        \n",
    "        for k in k_values:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                query_label = labels[i]\n",
    "                similarities = similarity_matrix[i]\n",
    "                similarities[i] = -float('inf')\n",
    "                \n",
    "                if k > len(labels) - 1:\n",
    "                    k_actual = len(labels) - 1\n",
    "                else:\n",
    "                    k_actual = k\n",
    "                \n",
    "                top_k_indices = torch.topk(similarities, k_actual).indices\n",
    "                top_k_labels = [labels[idx] for idx in top_k_indices]\n",
    "                \n",
    "                if query_label in top_k_labels:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "        \n",
    "        reciprocal_ranks = []\n",
    "        for i in range(len(labels)):\n",
    "            query_label = labels[i]\n",
    "            similarities = similarity_matrix[i]\n",
    "            similarities[i] = -float('inf')\n",
    "            \n",
    "            sorted_indices = torch.argsort(similarities, descending=True)\n",
    "            sorted_labels = [labels[idx] for idx in sorted_indices]\n",
    "            \n",
    "            try:\n",
    "                rank = sorted_labels.index(query_label) + 1\n",
    "                reciprocal_ranks.append(1.0 / rank)\n",
    "            except ValueError:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "        \n",
    "        results['mrr'] = np.mean(reciprocal_ranks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = torch.stack([torch.tensor(item['input_ids']) for item in batch])\n",
    "        attention_mask = torch.stack([torch.tensor(item['attention_mask']) for item in batch])\n",
    "        labels = torch.tensor([item['labels'] for item in batch])\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "    \n",
    "    def setup_optimizer(self, train_dataloader, num_epochs):\n",
    "        trainable_params = [p for p in self.base_model.parameters() if p.requires_grad]\n",
    "        trainable_params += list(self.classification_head.parameters())\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            trainable_params,\n",
    "            lr=2e-4,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        total_steps = len(train_dataloader) * num_epochs\n",
    "        warmup_steps = int(0.03 * total_steps)\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Optimizer setup complete. Total training steps: {total_steps}\")\n",
    "        logger.info(f\"Warmup steps: {warmup_steps}\")\n",
    "    \n",
    "    def train_epoch(self, train_dataloader, epoch, num_epochs):\n",
    "        self.base_model.eval()\n",
    "        self.classification_head.train()\n",
    "        \n",
    "        total_loss = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_dataloader):\n",
    "            first_device = next(self.base_model.parameters()).device\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(first_device)\n",
    "            attention_mask = batch['attention_mask'].to(first_device)\n",
    "            labels = batch['labels'].to(first_device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.base_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    output_hidden_states=True\n",
    "                )\n",
    "            \n",
    "            hidden_states = outputs.hidden_states[-1]\n",
    "            pooled = hidden_states.mean(dim=1)\n",
    "            \n",
    "            logits = self.classification_head(pooled).squeeze(-1)\n",
    "            \n",
    "            loss_fn = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fn(logits, labels.float())\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(self.base_model.parameters()) + list(self.classification_head.parameters()), \n",
    "                max_norm=1.0\n",
    "            )\n",
    "            \n",
    "            self.optimizer.step()\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_samples += input_ids.size(0)\n",
    "            \n",
    "            if batch_idx % 20 == 0:\n",
    "                current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                logger.info(\n",
    "                    f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                    f\"Batch {batch_idx}/{len(train_dataloader)} - \"\n",
    "                    f\"Loss: {loss.item():.4f} - \"\n",
    "                    f\"LR: {current_lr:.2e}\"\n",
    "                )\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        return {'loss': avg_loss}\n",
    "    \n",
    "    def train(self):\n",
    "        train_dataset = self.train_data.map(self.preprocess, batched=False)\n",
    "        test_dataset = self.test_data.map(self.preprocess, batched=False)\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"APPLYING BITFIT CONFIGURATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        self._setup_bitfit_parameters()\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        num_epochs = 5\n",
    "        \n",
    "        self.setup_optimizer(train_dataloader, num_epochs)\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING TRAINING\")\n",
    "        logger.info(f\"Total Epochs: {num_epochs}\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        training_start = time.time()\n",
    "        \n",
    "        process = psutil.Process(os.getpid())\n",
    "        mem_before = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            logger.info(f\"\\n{'='*60}\")\n",
    "            logger.info(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            logger.info(f\"{'='*60}\")\n",
    "            \n",
    "            train_metrics = self.train_epoch(train_dataloader, epoch, num_epochs)\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            self.training_stats['epoch_times'].append(epoch_time)\n",
    "            self.training_stats['epoch_losses'].append(train_metrics['loss'])\n",
    "            \n",
    "            logger.info(f\"Epoch {epoch+1} completed in {epoch_time:.2f}s\")\n",
    "            logger.info(f\"Training Loss: {train_metrics['loss']:.4f}\")\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        total_training_time = time.time() - training_start\n",
    "        \n",
    "        mem_after = process.memory_info().rss / 1024 / 1024\n",
    "        mem_used = mem_after - mem_before\n",
    "        \n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"TRAINING COMPLETE\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "        logger.info(f\"Average Epoch Time: {np.mean(self.training_stats['epoch_times']):.2f}s\")\n",
    "        logger.info(f\"Final Training Loss: {self.training_stats['epoch_losses'][-1]:.4f}\")\n",
    "        logger.info(f\"Memory Usage: {mem_used:.1f} MB\")\n",
    "        logger.info(f\"{'='*80}\\n\")\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        os.makedirs(\"codeqwen1.5-bitfit-clone\", exist_ok=True)\n",
    "        self.base_model.save_pretrained(\"codeqwen1.5-bitfit-clone\")\n",
    "        torch.save(self.classification_head.state_dict(), \"codeqwen1.5-bitfit-clone/classification_head.pt\")\n",
    "        logger.info(\"Models saved successfully to codeqwen1.5-bitfit-clone/\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return self.base_model, total_training_time\n",
    "    \n",
    "    def evaluate_comprehensive(self, model, test_dataset):\n",
    "        model.eval()\n",
    "        self.classification_head.eval()\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING COMPREHENSIVE EVALUATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        test_df = pd.read_csv(self.test_file)\n",
    "        test_labels = test_df[self.label_col].tolist()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_embeddings = []\n",
    "        \n",
    "        inference_start = time.time()\n",
    "        total_samples = len(test_dataset)\n",
    "        \n",
    "        logger.info(f\"Processing {total_samples} test samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx in range(len(test_dataset)):\n",
    "                sample = test_dataset[idx]\n",
    "                \n",
    "                input_ids = torch.tensor([sample['input_ids']])\n",
    "                attention_mask = torch.tensor([sample['attention_mask']])\n",
    "                \n",
    "                first_device = next(model.parameters()).device\n",
    "                input_ids = input_ids.to(first_device)\n",
    "                attention_mask = attention_mask.to(first_device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    output_hidden_states=True\n",
    "                )\n",
    "                \n",
    "                hidden_states = outputs.hidden_states[-1]\n",
    "                pooled = hidden_states.mean(dim=1)\n",
    "                \n",
    "                all_embeddings.append(pooled.squeeze().cpu())\n",
    "                \n",
    "                logits = self.classification_head(pooled).squeeze(-1)\n",
    "                \n",
    "                prob = torch.sigmoid(logits).item()\n",
    "                pred = 1 if prob > 0.5 else 0\n",
    "                \n",
    "                all_preds.append(pred)\n",
    "                all_probs.append(prob)\n",
    "                \n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    logger.info(f\"Processed {idx + 1}/{total_samples} samples\")\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        inference_time = time.time() - inference_start\n",
    "        samples_per_sec = total_samples / inference_time\n",
    "        \n",
    "        logger.info(f\"Inference completed in {inference_time:.2f}s\")\n",
    "        logger.info(f\"Throughput: {samples_per_sec:.2f} samples/sec\")\n",
    "        \n",
    "        metrics = self.calculate_metrics(test_labels, all_preds, all_probs)\n",
    "        \n",
    "        all_embeddings = torch.stack(all_embeddings)\n",
    "        recall_metrics = self.calculate_recall_at_k(all_embeddings, test_labels)\n",
    "        metrics.update(recall_metrics)\n",
    "        \n",
    "        metrics['inference_time'] = inference_time\n",
    "        metrics['samples_per_sec'] = samples_per_sec\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def print_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{metrics['cm']}\")\n",
    "    print(f\"\\nTrue Negatives (TN): {metrics['tn']}\")\n",
    "    print(f\"False Positives (FP): {metrics['fp']}\")\n",
    "    print(f\"False Negatives (FN): {metrics['fn']}\")\n",
    "    print(f\"True Positives (TP): {metrics['tp']}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLASSIFICATION METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {metrics['rec']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {metrics['npv']:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {metrics['fpr']:.4f}\")\n",
    "    print(f\"False Negative Rate (FNR): {metrics['fnr']:.4f}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ADVANCED METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Jaccard Score: {metrics['jacc']:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {metrics['mcc']:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PROBABILISTIC METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "    if 'pr_auc' in metrics:\n",
    "        print(f\"Precision-Recall AUC: {metrics['pr_auc']:.4f}\")\n",
    "    if 'log_loss' in metrics:\n",
    "        print(f\"Log Loss: {metrics['log_loss']:.4f}\")\n",
    "    if 'brier' in metrics:\n",
    "        print(f\"Brier Score: {metrics['brier']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RETRIEVAL METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@3: {metrics['recall@3']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    if 'inference_time' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PERFORMANCE METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "        print(f\"Throughput: {metrics['samples_per_sec']:.2f} samples/sec\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def run_bitfit_experiment(train_file, test_file, func1_col, func2_col, label_col, cache_dir=None, bias_terms=['all']):\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"CODE CLONE DETECTION WITH BITFIT\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    bitfit_trainer = BitFitCloneTrainer(\n",
    "        train_file, \n",
    "        test_file, \n",
    "        func1_col, \n",
    "        func2_col, \n",
    "        label_col,\n",
    "        cache_dir=cache_dir,\n",
    "        bias_terms=bias_terms\n",
    "    )\n",
    "    \n",
    "    model, training_time = bitfit_trainer.train()\n",
    "    \n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"FINAL TEST EVALUATION\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    test_dataset = bitfit_trainer.test_data.map(bitfit_trainer.preprocess, batched=False)\n",
    "    metrics = bitfit_trainer.evaluate_comprehensive(model, test_dataset)\n",
    "    \n",
    "    print_results(metrics, \"TEST SET\")\n",
    "    \n",
    "    return bitfit_trainer, model, metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_file = '/train.csv'\n",
    "    test_file = '/test.csv'\n",
    "    func1_col = \"func1\"\n",
    "    func2_col = \"func2\"\n",
    "    label_col = \"label\"\n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    try:\n",
    "        bitfit_trainer, model, results = run_bitfit_experiment(\n",
    "            train_file, \n",
    "            test_file, \n",
    "            func1_col, \n",
    "            func2_col, \n",
    "            label_col,\n",
    "            cache_dir=cache_dir,\n",
    "            bias_terms=['all']\n",
    "        )\n",
    "        logger.info(\"BitFit experiment completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fbdc23-86bb-4c5d-b181-11afaa29e197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GateRA codeQween"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3414a2a-de49-44a6-b8cb-f562e82df4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, balanced_accuracy_score, \n",
    "    matthews_corrcoef, roc_auc_score, average_precision_score, f1_score\n",
    ")\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Optional, List, Dict\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GateRAConfig:\n",
    "    rank: int = 16\n",
    "    alpha: float = 16.0\n",
    "    dropout: float = 0.0\n",
    "    target_modules: List[str] = None\n",
    "    entropy_reg_weight: float = 0.01\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.target_modules is None:\n",
    "            self.target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                                   \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "\n",
    "class GatingModule(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.gate_linear = nn.Linear(input_dim, 1, bias=True)\n",
    "        nn.init.zeros_(self.gate_linear.weight)\n",
    "        nn.init.zeros_(self.gate_linear.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        gate_logits = self.gate_linear(x)\n",
    "        gate_values = torch.sigmoid(gate_logits)\n",
    "        return gate_values\n",
    "\n",
    "\n",
    "class GateRALayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_layer: nn.Module,\n",
    "        rank: int,\n",
    "        alpha: float,\n",
    "        dropout: float,\n",
    "        input_dim: int,\n",
    "        output_dim: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        self.rank = rank\n",
    "        self.scaling = alpha / rank\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.zeros(input_dim, rank))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(rank, output_dim))\n",
    "        \n",
    "        self.gating_module = GatingModule(input_dim)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=dropout) if dropout > 0.0 else nn.Identity()\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.last_gate_values = None\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        base_output = self.base_layer(x)\n",
    "        \n",
    "        if x.dim() == 3:\n",
    "            batch_size, seq_len, hidden_dim = x.shape\n",
    "            x_flat = x.view(-1, hidden_dim)\n",
    "        else:\n",
    "            x_flat = x\n",
    "            batch_size, seq_len = None, None\n",
    "        \n",
    "        gate_values = self.gating_module(x_flat)\n",
    "        self.last_gate_values = gate_values.detach()\n",
    "        \n",
    "        lora_output = x_flat @ self.lora_A @ self.lora_B\n",
    "        lora_output = self.dropout_layer(lora_output)\n",
    "        \n",
    "        modulated_output = gate_values * lora_output * self.scaling\n",
    "        \n",
    "        if batch_size is not None and seq_len is not None:\n",
    "            modulated_output = modulated_output.view(batch_size, seq_len, -1)\n",
    "        \n",
    "        final_output = base_output + modulated_output\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "\n",
    "class CodeCloneDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class GateRACodeQwen(nn.Module):\n",
    "    def __init__(self, model_name: str, gatera_config: GateRAConfig, num_classes: int = 2, cache_dir: str = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Initializing model across {num_gpus} GPUs\")\n",
    "        \n",
    "        self.primary_device = 'cuda:0'\n",
    "        \n",
    "        print(\"Loading base LLM model...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            cache_dir=cache_dir,\n",
    "            low_cpu_mem_usage=True,\n",
    "            device_map='auto'\n",
    "        )\n",
    "        \n",
    "        self.llm = base_model\n",
    "        self.config = gatera_config\n",
    "        self.gatera_layers = nn.ModuleList()\n",
    "        self.gatera_layer_names = []\n",
    "        \n",
    "        total_layers = len(base_model.model.layers)\n",
    "        print(f\"Model has {total_layers} transformer layers\")\n",
    "        \n",
    "        self.layer_devices = []\n",
    "        for i in range(total_layers):\n",
    "            layer_device = next(base_model.model.layers[i].parameters()).device\n",
    "            self.layer_devices.append(str(layer_device))\n",
    "            if i % 5 == 0:\n",
    "                print(f\"  Layer {i} -> {layer_device}\")\n",
    "        \n",
    "        embed_device = next(base_model.model.embed_tokens.parameters()).device\n",
    "        norm_device = next(base_model.model.norm.parameters()).device\n",
    "        lm_head_device = next(base_model.lm_head.parameters()).device\n",
    "        \n",
    "        print(f\"Embeddings -> {embed_device}\")\n",
    "        print(f\"Norm -> {norm_device}\")\n",
    "        print(f\"LM Head -> {lm_head_device}\")\n",
    "        \n",
    "        self.embed_device = str(embed_device)\n",
    "        self.final_device = str(norm_device)\n",
    "        \n",
    "        self.hidden_size = base_model.config.hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        for param in self.llm.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        print(\"\\nInjecting GateRA layers...\")\n",
    "        self._inject_gatera_layers()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.hidden_size // 4, num_classes)\n",
    "        ).to(self.primary_device)\n",
    "        \n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data = module.weight.data.half()\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data = module.bias.data.half()\n",
    "        \n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        print(\"Model initialization complete!\")\n",
    "    \n",
    "    def _inject_gatera_layers(self):\n",
    "        layer_count = 0\n",
    "        for name, module in self.llm.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                layer_name = name.split('.')[-1]\n",
    "                \n",
    "                should_inject = any(target in layer_name for target in self.config.target_modules)\n",
    "                \n",
    "                if should_inject:\n",
    "                    input_dim = module.in_features\n",
    "                    output_dim = module.out_features\n",
    "                    \n",
    "                    layer_device = next(module.parameters()).device\n",
    "                    \n",
    "                    gatera_layer = GateRALayer(\n",
    "                        base_layer=module,\n",
    "                        rank=self.config.rank,\n",
    "                        alpha=self.config.alpha,\n",
    "                        dropout=self.config.dropout,\n",
    "                        input_dim=input_dim,\n",
    "                        output_dim=output_dim\n",
    "                    ).to(layer_device).half()\n",
    "                    \n",
    "                    self.gatera_layers.append(gatera_layer)\n",
    "                    self.gatera_layer_names.append(name)\n",
    "                    \n",
    "                    parent_name = '.'.join(name.split('.')[:-1])\n",
    "                    parent = self.llm\n",
    "                    if parent_name:\n",
    "                        for part in parent_name.split('.'):\n",
    "                            parent = getattr(parent, part)\n",
    "                    setattr(parent, layer_name, gatera_layer)\n",
    "                    \n",
    "                    layer_count += 1\n",
    "                    if layer_count % 10 == 0:\n",
    "                        print(f\"  Injected {layer_count} GateRA layers...\")\n",
    "        \n",
    "        print(f\"Total GateRA layers injected: {layer_count}\")\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        input_ids = input_ids.to(self.embed_device)\n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.to(self.embed_device)\n",
    "        \n",
    "        outputs = self.llm(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "        if str(hidden_states.device) != self.primary_device:\n",
    "            hidden_states = hidden_states.to(self.primary_device)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attention_mask_expanded = attention_mask.to(self.primary_device).unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "            attention_mask_expanded = attention_mask_expanded.half()\n",
    "            sum_embeddings = torch.sum(hidden_states * attention_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(attention_mask_expanded.sum(1), min=1e-9)\n",
    "            pooled_output = sum_embeddings / sum_mask\n",
    "        else:\n",
    "            pooled_output = hidden_states.mean(dim=1)\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if labels.device != logits.device:\n",
    "                labels = labels.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        return {'logits': logits, 'loss': loss, 'hidden_states': hidden_states}\n",
    "    \n",
    "    def get_gate_entropy_loss(self):\n",
    "        total_entropy_loss = 0.0\n",
    "        gate_count = 0\n",
    "        \n",
    "        for layer in self.gatera_layers:\n",
    "            if hasattr(layer, 'last_gate_values') and layer.last_gate_values is not None:\n",
    "                gate_values = layer.last_gate_values\n",
    "                eps = 1e-8\n",
    "                gate_values = torch.clamp(gate_values, eps, 1.0 - eps)\n",
    "                entropy = -gate_values * torch.log(gate_values) - (1 - gate_values) * torch.log(1 - gate_values)\n",
    "                # Move entropy to primary device before adding\n",
    "                total_entropy_loss += entropy.mean().to(self.primary_device)\n",
    "                gate_count += 1\n",
    "        \n",
    "        if gate_count > 0:\n",
    "            return total_entropy_loss / gate_count\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=self.primary_device)\n",
    "\n",
    "\n",
    "def print_parameter_statistics(model: GateRACodeQwen):\n",
    "    total_params = sum(p.numel() for p in model.llm.parameters())\n",
    "    \n",
    "    gatera_params = 0\n",
    "    for layer in model.gatera_layers:\n",
    "        gatera_params += sum(p.numel() for p in layer.parameters() if p.requires_grad)\n",
    "    \n",
    "    classifier_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "    trainable_params = gatera_params + classifier_params\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PARAMETER STATISTICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Frozen LLM Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable GateRA Parameters: {gatera_params:,}\")\n",
    "    print(f\"Trainable Classifier Parameters: {classifier_params:,}\")\n",
    "    print(f\"Total Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable Ratio: {(trainable_params / total_params * 100):.4f}%\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"GPU MEMORY USAGE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "        print(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "def load_dataset(csv_path, label_col, func1_col, func2_col):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded dataset: {len(df)} samples\")\n",
    "        print(f\"Label distribution: {df[label_col].value_counts().to_dict()}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_training_data(csv_path, tokenizer, max_length=512, \n",
    "                        label_col='label', func1_col='func1', func2_col='func2'):\n",
    "    df = load_dataset(csv_path, label_col, func1_col, func2_col)\n",
    "    \n",
    "    if df is None:\n",
    "        return []\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        func1 = str(row[func1_col])\n",
    "        func2 = str(row[func2_col])\n",
    "        label = int(row[label_col])\n",
    "        \n",
    "        combined_text = f\"Code1: {func1}\\nCode2: {func2}\\nAre these code clones?\"\n",
    "        \n",
    "        encoding = tokenizer(\n",
    "            combined_text,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        train_data.append({\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        })\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "\n",
    "def calculate_recall_at_k(embeddings, labels, k_values=[1, 5, 10]):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            true_label = labels[i]\n",
    "            sims = similarities[i].clone()\n",
    "            sims[i] = -float('inf')\n",
    "            \n",
    "            top_k_indices = torch.topk(sims, min(k, len(labels)-1)).indices\n",
    "            top_k_labels = labels[top_k_indices]\n",
    "            \n",
    "            if true_label in top_k_labels:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_mrr(embeddings, labels):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    mrr_sum = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        sims = similarities[i].clone()\n",
    "        sims[i] = -float('inf')\n",
    "        \n",
    "        sorted_indices = torch.argsort(sims, descending=True)\n",
    "        sorted_labels = labels[sorted_indices]\n",
    "        \n",
    "        for rank, label in enumerate(sorted_labels, 1):\n",
    "            if label == true_label:\n",
    "                mrr_sum += 1.0 / rank\n",
    "                break\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return mrr_sum / count if count > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, y_proba=None, embeddings=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    if cm.shape != (2, 2):\n",
    "        cm_2x2 = np.zeros((2, 2))\n",
    "        for i in range(min(cm.shape[0], 2)):\n",
    "            for j in range(min(cm.shape[1], 2)):\n",
    "                cm_2x2[i, j] = cm[i, j]\n",
    "        cm = cm_2x2\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    \n",
    "    if y_proba is not None and len(np.unique(y_true)) > 1:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_proba)\n",
    "            pr_auc = average_precision_score(y_true, y_proba)\n",
    "        except:\n",
    "            roc_auc = pr_auc = 0.0\n",
    "    else:\n",
    "        roc_auc = pr_auc = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'cm': cm,\n",
    "        'acc': acc,\n",
    "        'bal_acc': bal_acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'specificity': specificity,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc\n",
    "    }\n",
    "    \n",
    "    if embeddings is not None:\n",
    "        recall_metrics = calculate_recall_at_k(embeddings, torch.tensor(y_true))\n",
    "        mrr = calculate_mrr(embeddings, torch.tensor(y_true))\n",
    "        results.update(recall_metrics)\n",
    "        results['mrr'] = mrr\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "\n",
    "def train_model(model, train_data, num_epochs=5, learning_rate=1e-4, batch_size=2, entropy_reg_weight=0.01):\n",
    "    # Collect trainable parameters\n",
    "    trainable_params = []\n",
    "    for layer in model.gatera_layers:\n",
    "        trainable_params.extend([p for p in layer.parameters() if p.requires_grad])\n",
    "    trainable_params.extend([p for p in model.classifier.parameters() if p.requires_grad])\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    dataset = CodeCloneDataset(train_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_stats = []\n",
    "    start_time = time.time()\n",
    "    initial_memory = get_memory_usage()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        total_loss = 0\n",
    "        total_task_loss = 0\n",
    "        total_entropy_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batch_count = 0\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            total_tokens += input_ids.numel()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            task_loss = outputs['loss']\n",
    "            \n",
    "            # Get entropy regularization loss\n",
    "            entropy_loss = model.get_gate_entropy_loss()\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = task_loss + entropy_reg_weight * entropy_loss\n",
    "            \n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(trainable_params, 1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_task_loss += task_loss.item()\n",
    "                total_entropy_loss += entropy_loss.item()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                    correct += (predictions == labels.to(predictions.device)).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            \n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "        avg_task_loss = total_task_loss / batch_count if batch_count > 0 else 0\n",
    "        avg_entropy_loss = total_entropy_loss / batch_count if batch_count > 0 else 0\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        tokens_per_sec = total_tokens / epoch_time\n",
    "        current_memory = get_memory_usage()\n",
    "        \n",
    "        epoch_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': avg_loss,\n",
    "            'task_loss': avg_task_loss,\n",
    "            'entropy_loss': avg_entropy_loss,\n",
    "            'acc': accuracy,\n",
    "            'time': epoch_time,\n",
    "            'tokens_per_sec': tokens_per_sec,\n",
    "            'memory_mb': current_memory\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} (Task: {avg_task_loss:.4f}, Entropy: {avg_entropy_loss:.4f}), \"\n",
    "              f\"Acc: {accuracy:.4f}, Time: {epoch_time:.2f}s, Tokens/sec: {tokens_per_sec:.2f}, Memory: {current_memory:.2f}MB\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            print(f\"  GPU {i} Memory: {allocated:.2f} GB\")\n",
    "    \n",
    "    total_training_time = time.time() - start_time\n",
    "    peak_memory = max([stat['memory_mb'] for stat in epoch_stats])\n",
    "    memory_increase = peak_memory - initial_memory\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "    print(f\"Peak Memory Usage: {peak_memory:.2f}MB\")\n",
    "    print(f\"Memory Increase: {memory_increase:.2f}MB\")\n",
    "    print(f\"Average Tokens/sec: {np.mean([s['tokens_per_sec'] for s in epoch_stats]):.2f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return epoch_stats\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, batch_size=2):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    all_embeddings = []\n",
    "    \n",
    "    dataset = CodeCloneDataset(test_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            total_tokens += input_ids.numel()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            hidden_states = outputs['hidden_states']\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            pooled_embeddings = hidden_states.mean(dim=1)\n",
    "            pooled_embeddings = F.normalize(pooled_embeddings, p=2, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())\n",
    "            all_embeddings.append(pooled_embeddings.cpu())\n",
    "            \n",
    "            if len(all_predictions) % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    tokens_per_sec = total_tokens / inference_time\n",
    "    \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    metrics = calculate_comprehensive_metrics(\n",
    "        all_labels, \n",
    "        all_predictions, \n",
    "        all_probabilities,\n",
    "        all_embeddings\n",
    "    )\n",
    "    \n",
    "    metrics['inference_time'] = inference_time\n",
    "    metrics['tokens_per_sec'] = tokens_per_sec\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_evaluation_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EVALUATION RESULTS - {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['cm']}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall: {metrics['rec']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"MCC: {metrics['mcc']:.4f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"MRR: {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "    print(f\"Tokens/sec: {metrics['tokens_per_sec']:.2f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    primary_device = 'cuda:0'\n",
    "    \n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/CodeQwen1.5-7B-Chat\", cache_dir=cache_dir)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Create GateRA config\n",
    "    gatera_config = GateRAConfig(\n",
    "        rank=16,\n",
    "        alpha=16.0,\n",
    "        dropout=0.0,\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        entropy_reg_weight=0.01\n",
    "    )\n",
    "    \n",
    "    print(\"\\nLoading model with GateRA PEFT and pipeline parallelism across GPUs...\")\n",
    "    model = GateRACodeQwen(\"Qwen/CodeQwen1.5-7B-Chat\", gatera_config=gatera_config, num_classes=2, cache_dir=cache_dir)\n",
    "    print_parameter_statistics(model)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    train_csv = '/train.csv'\n",
    "    train_data = create_training_data(\n",
    "        train_csv, \n",
    "        tokenizer,\n",
    "        label_col='label', \n",
    "        func1_col='func1', \n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(train_data)} training examples\\n\")\n",
    "    \n",
    "    if len(train_data) == 0:\n",
    "        print(\"No training data available. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    epoch_stats = train_model(\n",
    "        model, \n",
    "        train_data, \n",
    "        num_epochs=5, \n",
    "        learning_rate=1e-4, \n",
    "        batch_size=2,\n",
    "        entropy_reg_weight=gatera_config.entropy_reg_weight\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TESTING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    test_csv = '/test.csv'\n",
    "    test_data = create_training_data(\n",
    "        test_csv,\n",
    "        tokenizer,\n",
    "        label_col='label',\n",
    "        func1_col='func1',\n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(test_data)} test examples\\n\")\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        test_metrics = evaluate_model(model, test_data, batch_size=2)\n",
    "        print_evaluation_results(test_metrics, \"TEST SET\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72bacc6-6d46-4e8f-9e1d-ed0ce8a63aa9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# codeqwuen prefix tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb6ce1-a79b-4472-aeec-83c1f09d2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, balanced_accuracy_score, \n",
    "    matthews_corrcoef, roc_auc_score, average_precision_score, \n",
    "    f1_score, jaccard_score, cohen_kappa_score, log_loss, brier_score_loss\n",
    ")\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class PrefixTuningConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        prefix_length: int = 20,\n",
    "        num_layers: int = 32,\n",
    "        hidden_size: int = 4096,\n",
    "        num_heads: int = 32,\n",
    "        head_dim: int = 128,\n",
    "        reparam_dim: int = 512,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        self.prefix_length = prefix_length\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.reparam_dim = reparam_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "\n",
    "class PrefixEncoder(nn.Module):\n",
    "    def __init__(self, config: PrefixTuningConfig):\n",
    "        super().__init__()\n",
    "        self.prefix_length = config.prefix_length\n",
    "        self.num_layers = config.num_layers\n",
    "        self.num_heads = config.num_heads\n",
    "        self.head_dim = config.head_dim\n",
    "        self.hidden_size = config.hidden_size\n",
    "        \n",
    "        self.prefix_tokens = nn.Parameter(\n",
    "            torch.randn(config.num_layers, config.prefix_length, config.reparam_dim)\n",
    "        )\n",
    "        \n",
    "        self.reparam_mlp = nn.Sequential(\n",
    "            nn.Linear(config.reparam_dim, config.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(config.hidden_size, 2 * config.num_heads * config.head_dim),\n",
    "            nn.Dropout(config.dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch_size: int):\n",
    "        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "        \n",
    "        prefix_kvs = []\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            layer_prefix = prefix_tokens[:, layer_idx, :, :]\n",
    "            prefix_hidden = self.reparam_mlp(layer_prefix)\n",
    "            \n",
    "            prefix_hidden = prefix_hidden.view(\n",
    "                batch_size, self.prefix_length, 2, self.num_heads, self.head_dim\n",
    "            )\n",
    "            \n",
    "            key = prefix_hidden[:, :, 0, :, :].transpose(1, 2)\n",
    "            value = prefix_hidden[:, :, 1, :, :].transpose(1, 2)\n",
    "            \n",
    "            prefix_kvs.append((key.contiguous(), value.contiguous()))\n",
    "        \n",
    "        return prefix_kvs\n",
    "\n",
    "\n",
    "class CodeCloneDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "class PrefixTuningCodeQwen(nn.Module):\n",
    "    def __init__(self, model_name: str, prefix_config: PrefixTuningConfig, num_classes: int = 2, cache_dir: str = None):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Initializing model across {num_gpus} GPUs\")\n",
    "        \n",
    "        self.primary_device = 'cuda:0'\n",
    "        \n",
    "        print(\"Loading base LLM model...\")\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            cache_dir=cache_dir,\n",
    "            low_cpu_mem_usage=True,\n",
    "            device_map='auto'\n",
    "        )\n",
    "        \n",
    "        self.llm = base_model\n",
    "        self.prefix_config = prefix_config\n",
    "        \n",
    "        total_layers = len(base_model.model.layers)\n",
    "        print(f\"Model has {total_layers} transformer layers\")\n",
    "        \n",
    "        self.layer_devices = []\n",
    "        for i in range(total_layers):\n",
    "            layer_device = next(base_model.model.layers[i].parameters()).device\n",
    "            self.layer_devices.append(str(layer_device))\n",
    "            if i % 5 == 0:\n",
    "                print(f\"  Layer {i} -> {layer_device}\")\n",
    "        \n",
    "        embed_device = next(base_model.model.embed_tokens.parameters()).device\n",
    "        norm_device = next(base_model.model.norm.parameters()).device\n",
    "        \n",
    "        print(f\"Embeddings -> {embed_device}\")\n",
    "        print(f\"Norm -> {norm_device}\")\n",
    "        \n",
    "        self.embed_device = str(embed_device)\n",
    "        self.final_device = str(norm_device)\n",
    "        \n",
    "        self.prefix_encoder = PrefixEncoder(prefix_config).to(self.primary_device).half()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(prefix_config.hidden_size, prefix_config.hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(prefix_config.hidden_size // 4, num_classes)\n",
    "        ).to(self.primary_device).half()\n",
    "        \n",
    "        for param in self.llm.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        for param in self.prefix_encoder.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        self._register_prefix_hooks()\n",
    "        \n",
    "        print(\"Model initialization complete!\")\n",
    "    \n",
    "    def _register_prefix_hooks(self):\n",
    "        self.prefix_kvs = None\n",
    "        \n",
    "        def create_hook(layer_idx):\n",
    "            def hook(module, args, kwargs, output):\n",
    "                if self.prefix_kvs is not None and layer_idx < len(self.prefix_kvs):\n",
    "                    prefix_key, prefix_value = self.prefix_kvs[layer_idx]\n",
    "                    \n",
    "                    device = output.past_key_value[0].device if hasattr(output, 'past_key_value') and output.past_key_value is not None else self.layer_devices[layer_idx]\n",
    "                    \n",
    "                    prefix_key = prefix_key.to(device)\n",
    "                    prefix_value = prefix_value.to(device)\n",
    "                    \n",
    "                    if hasattr(output, 'past_key_value') and output.past_key_value is not None:\n",
    "                        orig_key, orig_value = output.past_key_value\n",
    "                        \n",
    "                        new_key = torch.cat([prefix_key, orig_key], dim=2)\n",
    "                        new_value = torch.cat([prefix_value, orig_value], dim=2)\n",
    "                        \n",
    "                        output.past_key_value = (new_key, new_value)\n",
    "                \n",
    "                return output\n",
    "            return hook\n",
    "        \n",
    "        for layer_idx, layer in enumerate(self.llm.model.layers):\n",
    "            layer.register_forward_hook(create_hook(layer_idx), with_kwargs=True)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        input_ids = input_ids.to(self.embed_device)\n",
    "        \n",
    "        self.prefix_kvs = self.prefix_encoder(batch_size)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attention_mask = attention_mask.to(self.embed_device)\n",
    "            prefix_attention = torch.ones(\n",
    "                batch_size, self.prefix_config.prefix_length, \n",
    "                dtype=attention_mask.dtype, device=attention_mask.device\n",
    "            )\n",
    "            attention_mask = torch.cat([prefix_attention, attention_mask], dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.llm(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True,\n",
    "                use_cache=True\n",
    "            )\n",
    "        \n",
    "        hidden_states = outputs.hidden_states[-1]\n",
    "        \n",
    "        if str(hidden_states.device) != self.primary_device:\n",
    "            hidden_states = hidden_states.to(self.primary_device)\n",
    "        \n",
    "        pooled_output = hidden_states.mean(dim=1)\n",
    "        \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if labels.device != logits.device:\n",
    "                labels = labels.to(logits.device)\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "        \n",
    "        self.prefix_kvs = None\n",
    "        \n",
    "        return {'logits': logits, 'loss': loss, 'hidden_states': hidden_states}\n",
    "\n",
    "\n",
    "def print_parameter_statistics(model: PrefixTuningCodeQwen):\n",
    "    total_params = sum(p.numel() for p in model.llm.parameters())\n",
    "    prefix_params = sum(p.numel() for p in model.prefix_encoder.parameters())\n",
    "    classifier_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "    trainable_params = prefix_params + classifier_params\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PARAMETER STATISTICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Frozen LLM Parameters: {total_params:,}\")\n",
    "    print(f\"Trainable Prefix Parameters: {prefix_params:,}\")\n",
    "    print(f\"Trainable Classifier Parameters: {classifier_params:,}\")\n",
    "    print(f\"Total Trainable Parameters: {trainable_params:,}\")\n",
    "    print(f\"Trainable Percentage: {(trainable_params / total_params * 100):.4f}%\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"GPU MEMORY USAGE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "        print(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def load_dataset(csv_path, label_col, func1_col, func2_col):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded dataset: {len(df)} samples\")\n",
    "        print(f\"Label distribution: {df[label_col].value_counts().to_dict()}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_training_data(csv_path, tokenizer, max_length=512, \n",
    "                        label_col='label', func1_col='func1', func2_col='func2'):\n",
    "    df = load_dataset(csv_path, label_col, func1_col, func2_col)\n",
    "    \n",
    "    if df is None:\n",
    "        return []\n",
    "    \n",
    "    train_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        func1 = str(row[func1_col])\n",
    "        func2 = str(row[func2_col])\n",
    "        label = int(row[label_col])\n",
    "        \n",
    "        combined_text = f\"Code1: {func1}\\nCode2: {func2}\\nAre these code clones?\"\n",
    "        \n",
    "        encoding = tokenizer(\n",
    "            combined_text,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        train_data.append({\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        })\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "\n",
    "def calculate_recall_at_k(embeddings, labels, k_values=[1, 3, 5, 10]):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            true_label = labels[i]\n",
    "            sims = similarities[i].clone()\n",
    "            sims[i] = -float('inf')\n",
    "            \n",
    "            top_k_indices = torch.topk(sims, min(k, len(labels)-1)).indices\n",
    "            top_k_labels = labels[top_k_indices]\n",
    "            \n",
    "            if true_label in top_k_labels:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        \n",
    "        results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_mrr(embeddings, labels):\n",
    "    similarities = torch.mm(embeddings, embeddings.t())\n",
    "    \n",
    "    mrr_sum = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        true_label = labels[i]\n",
    "        sims = similarities[i].clone()\n",
    "        sims[i] = -float('inf')\n",
    "        \n",
    "        sorted_indices = torch.argsort(sims, descending=True)\n",
    "        sorted_labels = labels[sorted_indices]\n",
    "        \n",
    "        for rank, label in enumerate(sorted_labels, 1):\n",
    "            if label == true_label:\n",
    "                mrr_sum += 1.0 / rank\n",
    "                break\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    return mrr_sum / count if count > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_comprehensive_metrics(y_true, y_pred, y_proba=None, embeddings=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    if cm.shape != (2, 2):\n",
    "        cm_2x2 = np.zeros((2, 2))\n",
    "        for i in range(min(cm.shape[0], 2)):\n",
    "            for j in range(min(cm.shape[1], 2)):\n",
    "                cm_2x2[i, j] = cm[i, j]\n",
    "        cm = cm_2x2\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "    jacc = jaccard_score(y_true, y_pred, zero_division=0)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    if y_proba is not None and len(np.unique(y_true)) > 1:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_true, y_proba)\n",
    "            pr_auc = average_precision_score(y_true, y_proba)\n",
    "            logloss = log_loss(y_true, np.column_stack([1-y_proba, y_proba]))\n",
    "            brier = brier_score_loss(y_true, y_proba)\n",
    "        except:\n",
    "            roc_auc = pr_auc = logloss = brier = 0.0\n",
    "    else:\n",
    "        roc_auc = pr_auc = logloss = brier = 0.0\n",
    "    \n",
    "    results = {\n",
    "        'cm': cm,\n",
    "        'tn': int(tn),\n",
    "        'fp': int(fp),\n",
    "        'fn': int(fn),\n",
    "        'tp': int(tp),\n",
    "        'acc': acc,\n",
    "        'bal_acc': bal_acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'specificity': specificity,\n",
    "        'npv': npv,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'f1': f1,\n",
    "        'mcc': mcc,\n",
    "        'jacc': jacc,\n",
    "        'kappa': kappa,\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'log_loss': logloss,\n",
    "        'brier': brier\n",
    "    }\n",
    "    \n",
    "    if embeddings is not None:\n",
    "        recall_metrics = calculate_recall_at_k(embeddings, torch.tensor(y_true))\n",
    "        mrr = calculate_mrr(embeddings, torch.tensor(y_true))\n",
    "        results.update(recall_metrics)\n",
    "        results['mrr'] = mrr\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "\n",
    "def train_model(model, train_data, num_epochs=5, learning_rate=1e-4, batch_size=2):\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': model.prefix_encoder.parameters()},\n",
    "        {'params': model.classifier.parameters()}\n",
    "    ], lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    dataset = CodeCloneDataset(train_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_stats = []\n",
    "    start_time = time.time()\n",
    "    initial_memory = get_memory_usage()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            loss = outputs['loss']\n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    list(model.prefix_encoder.parameters()) + list(model.classifier.parameters()), 1.0\n",
    "                )\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    predictions = torch.argmax(outputs['logits'], dim=-1)\n",
    "                    correct += (predictions == labels.to(predictions.device)).sum().item()\n",
    "                    total += labels.size(0)\n",
    "            \n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        current_memory = get_memory_usage()\n",
    "        \n",
    "        epoch_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'loss': avg_loss,\n",
    "            'acc': accuracy,\n",
    "            'time': epoch_time,\n",
    "            'memory_mb': current_memory\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, Acc: {accuracy:.4f}, Time: {epoch_time:.2f}s, Memory: {current_memory:.2f}MB\")\n",
    "        \n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            print(f\"  GPU {i} Memory: {allocated:.2f} GB\")\n",
    "    \n",
    "    total_training_time = time.time() - start_time\n",
    "    peak_memory = max([stat['memory_mb'] for stat in epoch_stats])\n",
    "    memory_increase = peak_memory - initial_memory\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "    print(f\"Peak Memory Usage: {peak_memory:.2f}MB\")\n",
    "    print(f\"Memory Increase: {memory_increase:.2f}MB\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return epoch_stats\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, batch_size=2):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    all_embeddings = []\n",
    "    \n",
    "    dataset = CodeCloneDataset(test_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "            input_ids = batch_data['input_ids']\n",
    "            attention_mask = batch_data['attention_mask']\n",
    "            labels = batch_data['labels']\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            hidden_states = outputs['hidden_states']\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            probabilities = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            pooled_embeddings = hidden_states.mean(dim=1)\n",
    "            pooled_embeddings = F.normalize(pooled_embeddings, p=2, dim=1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())\n",
    "            all_embeddings.append(pooled_embeddings.cpu())\n",
    "            \n",
    "            if len(all_predictions) % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    samples_per_sec = len(test_data) / inference_time\n",
    "    \n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    metrics = calculate_comprehensive_metrics(\n",
    "        all_labels, \n",
    "        all_predictions, \n",
    "        all_probabilities,\n",
    "        all_embeddings\n",
    "    )\n",
    "    \n",
    "    metrics['inference_time'] = inference_time\n",
    "    metrics['samples_per_sec'] = samples_per_sec\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{metrics['cm']}\")\n",
    "    print(f\"\\nTrue Negatives (TN): {metrics['tn']}\")\n",
    "    print(f\"False Positives (FP): {metrics['fp']}\")\n",
    "    print(f\"False Negatives (FN): {metrics['fn']}\")\n",
    "    print(f\"True Positives (TP): {metrics['tp']}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLASSIFICATION METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {metrics['rec']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {metrics['npv']:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {metrics['fpr']:.4f}\")\n",
    "    print(f\"False Negative Rate (FNR): {metrics['fnr']:.4f}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ADVANCED METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Jaccard Score: {metrics['jacc']:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {metrics['mcc']:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PROBABILISTIC METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "    if 'pr_auc' in metrics:\n",
    "        print(f\"Precision-Recall AUC: {metrics['pr_auc']:.4f}\")\n",
    "    if 'log_loss' in metrics:\n",
    "        print(f\"Log Loss: {metrics['log_loss']:.4f}\")\n",
    "    if 'brier' in metrics:\n",
    "        print(f\"Brier Score: {metrics['brier']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RETRIEVAL METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@3: {metrics['recall@3']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    if 'inference_time' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PERFORMANCE METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "        print(f\"Throughput: {metrics['samples_per_sec']:.2f} samples/sec\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Qwen/CodeQwen1.5-7B-Chat\", cache_dir=cache_dir)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    prefix_config = PrefixTuningConfig(\n",
    "        prefix_length=20,\n",
    "        num_layers=32,\n",
    "        hidden_size=4096,\n",
    "        num_heads=32,\n",
    "        head_dim=128,\n",
    "        reparam_dim=512\n",
    "    )\n",
    "    \n",
    "    print(\"\\nLoading model with pipeline parallelism across GPUs...\")\n",
    "    model = PrefixTuningCodeQwen(\"Qwen/CodeQwen1.5-7B-Chat\", prefix_config, num_classes=2, cache_dir=cache_dir)\n",
    "    print_parameter_statistics(model)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    train_csv = '/train.csv'\n",
    "    train_data = create_training_data(\n",
    "        train_csv, \n",
    "        tokenizer,\n",
    "        label_col='label', \n",
    "        func1_col='func1', \n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(train_data)} training examples\\n\")\n",
    "    \n",
    "    if len(train_data) == 0:\n",
    "        print(\"No training data available. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    epoch_stats = train_model(model, train_data, num_epochs=5, learning_rate=1e-4, batch_size=2)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TESTING PHASE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    test_csv = '/test.csv'\n",
    "    test_data = create_training_data(\n",
    "        test_csv,\n",
    "        tokenizer,\n",
    "        label_col='label',\n",
    "        func1_col='func1',\n",
    "        func2_col='func2'\n",
    "    )\n",
    "    print(f\"Created {len(test_data)} test examples\\n\")\n",
    "    \n",
    "    if len(test_data) > 0:\n",
    "        test_metrics = evaluate_model(model, test_data, batch_size=2)\n",
    "        print_results(test_metrics, \"TEST SET\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1efcf8-16eb-4cfd-a44f-51c2b19ac7ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ts-pEFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc694de-2b6c-482f-b461-6d79cc2562c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, confusion_matrix,\n",
    "    balanced_accuracy_score, precision_score, recall_score, jaccard_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, roc_auc_score, average_precision_score,\n",
    "    log_loss, brier_score_loss\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        rank: int = 4,\n",
    "        alpha: float = 1.0,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank\n",
    "        \n",
    "        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result = self.dropout(x) @ self.lora_A.T @ self.lora_B.T\n",
    "        return result * self.scaling\n",
    "\n",
    "\n",
    "class TSPEFTLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_layer: nn.Linear,\n",
    "        rank: int = 4,\n",
    "        alpha: float = 1.0,\n",
    "        dropout: float = 0.0,\n",
    "        s: float = 4e-5,\n",
    "        lambda_reg: float = 1e-5,\n",
    "        beta1: float = 0.9,\n",
    "        beta2: float = 0.98,\n",
    "        eps: float = 1e-8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        self.base_layer.requires_grad_(False)\n",
    "        \n",
    "        base_dtype = base_layer.weight.dtype\n",
    "        \n",
    "        self.lora = LoRALayer(\n",
    "            base_layer.in_features,\n",
    "            base_layer.out_features,\n",
    "            rank=rank,\n",
    "            alpha=alpha,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.lora.lora_A.data = self.lora.lora_A.data.to(base_dtype)\n",
    "            self.lora.lora_B.data = self.lora.lora_B.data.to(base_dtype)\n",
    "        \n",
    "        self.s = s\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        \n",
    "        self.register_buffer('tau', torch.tensor(0.0, dtype=base_dtype))\n",
    "        self.register_buffer('m', torch.tensor(0.0, dtype=base_dtype))\n",
    "        self.register_buffer('v', torch.tensor(0.0, dtype=base_dtype))\n",
    "        self.register_buffer('step', torch.tensor(0))\n",
    "        \n",
    "    def compute_relative_magnitude(\n",
    "        self, \n",
    "        base_output: torch.Tensor, \n",
    "        lora_output: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        base_norm = torch.norm(base_output, p=2, dim=-1, keepdim=True)\n",
    "        lora_norm = torch.norm(lora_output, p=2, dim=-1, keepdim=True)\n",
    "        r_i = lora_norm / (base_norm + self.eps)\n",
    "        return r_i.squeeze(-1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.to(dtype=self.base_layer.weight.dtype)\n",
    "        \n",
    "        base_output = self.base_layer(x)\n",
    "        lora_output = self.lora(x)\n",
    "        \n",
    "        if not self.training:\n",
    "            r_i = self.compute_relative_magnitude(base_output, lora_output)\n",
    "            gate = (r_i >= self.tau).float().unsqueeze(-1)\n",
    "            return base_output + gate * lora_output\n",
    "        \n",
    "        r_i = self.compute_relative_magnitude(base_output, lora_output)\n",
    "        gate = (r_i >= self.tau).float()\n",
    "        \n",
    "        gated_output = base_output + gate.unsqueeze(-1) * lora_output\n",
    "        \n",
    "        self._cache_for_backward = {\n",
    "            'r_i': r_i,\n",
    "            'gate': gate,\n",
    "            'lora_output': lora_output,\n",
    "            'base_output': base_output,\n",
    "        }\n",
    "        \n",
    "        return gated_output\n",
    "        \n",
    "    def compute_threshold_gradient(self, grad_output: torch.Tensor) -> float:\n",
    "        if not hasattr(self, '_cache_for_backward'):\n",
    "            return 0.0\n",
    "            \n",
    "        cache = self._cache_for_backward\n",
    "        r_i = cache['r_i']\n",
    "        gate = cache['gate']\n",
    "        lora_output = cache['lora_output']\n",
    "        \n",
    "        mu_i = (grad_output * lora_output).sum(dim=-1)\n",
    "        \n",
    "        consistency_mask = ((mu_i >= 0).float() == gate).float()\n",
    "        sparsity_mask = gate\n",
    "        \n",
    "        grad_loss = -self.s * (consistency_mask * mu_i).sum()\n",
    "        grad_sparsity = -self.s * (sparsity_mask * self.lambda_reg).sum()\n",
    "        \n",
    "        g_k = grad_loss + grad_sparsity\n",
    "        \n",
    "        return g_k.item()\n",
    "    \n",
    "    def update_threshold(self, grad_output: torch.Tensor, lr: float = 1.0):\n",
    "        if not self.training:\n",
    "            return\n",
    "            \n",
    "        g_k = self.compute_threshold_gradient(grad_output)\n",
    "        \n",
    "        self.step += 1\n",
    "        \n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * g_k\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (g_k ** 2)\n",
    "        \n",
    "        m_hat = self.m / (1 - self.beta1 ** self.step.item())\n",
    "        v_hat = self.v / (1 - self.beta2 ** self.step.item())\n",
    "        \n",
    "        tau_update = lr * self.s * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "        self.tau = torch.clamp(self.tau + tau_update, min=0.0)\n",
    "        \n",
    "        if hasattr(self, '_cache_for_backward'):\n",
    "            delattr(self, '_cache_for_backward')\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size, num_labels=1, dtype=torch.float16):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size, dtype=dtype)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.out_proj = nn.Linear(hidden_size, num_labels, dtype=dtype)\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        x = self.dropout(hidden_states)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TSPEFTCloneTrainer:\n",
    "    def __init__(self, train_file, test_file, func1_col, func2_col, label_col, cache_dir=None, \n",
    "                 rank=32, alpha=0.5, dropout=0.05, s=4e-5, lambda_reg=4.5e-5):\n",
    "        self.train_file = train_file\n",
    "        self.test_file = test_file\n",
    "        self.func1_col = func1_col\n",
    "        self.func2_col = func2_col\n",
    "        self.label_col = label_col\n",
    "        self.cache_dir = cache_dir\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.dropout = dropout\n",
    "        self.s = s\n",
    "        self.lambda_reg = lambda_reg\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        logger.info(f\"Number of available GPUs: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            logger.info(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "        logger.info(\"Loading tokenizer...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\", \n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True\n",
    "        )\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        logger.info(\"Loading base model with automatic device mapping...\")\n",
    "        self.base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"Qwen/CodeQwen1.5-7B-Chat\",\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir,\n",
    "            local_files_only=True,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.base_model.config.hidden_size\n",
    "        logger.info(f\"Model hidden size: {hidden_size}\")\n",
    "        \n",
    "        self.classification_head = None\n",
    "        self.ts_peft_layers = {}\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        logger.info(\"Loading datasets...\")\n",
    "        self.train_data = HFDataset.from_csv(train_file)\n",
    "        self.test_data = HFDataset.from_csv(test_file)\n",
    "        logger.info(f\"Train samples: {len(self.train_data)}\")\n",
    "        logger.info(f\"Test samples: {len(self.test_data)}\")\n",
    "        \n",
    "        self.training_stats = {\n",
    "            'epoch_times': [],\n",
    "            'epoch_losses': [],\n",
    "            'memory_usage': []\n",
    "        }\n",
    "        \n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "    \n",
    "    def print_model_distribution(self):\n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"MODEL DEVICE DISTRIBUTION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        if hasattr(self.base_model, 'hf_device_map'):\n",
    "            device_map = self.base_model.hf_device_map\n",
    "            for module_name, device in device_map.items():\n",
    "                logger.info(f\"{module_name}: {device}\")\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"GPU MEMORY USAGE\")\n",
    "        logger.info(\"=\"*80)\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "            logger.info(f\"GPU {i}: Allocated: {allocated:.2f} GB, Reserved: {reserved:.2f} GB\")\n",
    "        logger.info(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    def preprocess(self, example):\n",
    "        c1 = example[self.func1_col]\n",
    "        c2 = example[self.func2_col]\n",
    "        y = example[self.label_col]\n",
    "        text = f\"<func1>\\n{c1}\\n</func1>\\n<func2>\\n{c2}\\n</func2>\"\n",
    "        out = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=512)\n",
    "        out[\"labels\"] = y\n",
    "        return out\n",
    "    \n",
    "    def _setup_tspeft_parameters(self):\n",
    "        logger.info(\"Setting up TS-PEFT parameters...\")\n",
    "        \n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'down_proj', 'gate_proj']\n",
    "        \n",
    "        trainable_params = 0\n",
    "        total_params = 0\n",
    "        lora_param_count = 0\n",
    "        \n",
    "        for name, module in self.base_model.named_modules():\n",
    "            total_params += sum(p.numel() for p in module.parameters(recurse=False))\n",
    "            \n",
    "            if isinstance(module, nn.Linear):\n",
    "                should_replace = False\n",
    "                for target in target_modules:\n",
    "                    if target in name:\n",
    "                        should_replace = True\n",
    "                        break\n",
    "                \n",
    "                if should_replace:\n",
    "                    parent_name = '.'.join(name.split('.')[:-1])\n",
    "                    child_name = name.split('.')[-1]\n",
    "                    \n",
    "                    parent = self.base_model\n",
    "                    if parent_name:\n",
    "                        for part in parent_name.split('.'):\n",
    "                            parent = getattr(parent, part)\n",
    "                    \n",
    "                    module_device = next(module.parameters()).device\n",
    "                    module_dtype = next(module.parameters()).dtype\n",
    "                    \n",
    "                    ts_layer = TSPEFTLayer(\n",
    "                        module,\n",
    "                        rank=self.rank,\n",
    "                        alpha=self.alpha,\n",
    "                        dropout=self.dropout,\n",
    "                        s=self.s,\n",
    "                        lambda_reg=self.lambda_reg,\n",
    "                    )\n",
    "                    \n",
    "                    ts_layer = ts_layer.to(device=module_device, dtype=module_dtype)\n",
    "                    \n",
    "                    setattr(parent, child_name, ts_layer)\n",
    "                    layer_key = name.replace('.', '_')\n",
    "                    self.ts_peft_layers[layer_key] = ts_layer\n",
    "                    \n",
    "                    lora_params = sum(p.numel() for p in ts_layer.lora.parameters())\n",
    "                    trainable_params += lora_params\n",
    "                    lora_param_count += lora_params\n",
    "                    \n",
    "                    logger.info(f\" TS-PEFT Layer: {name} on {module_device} - LoRA Params: {lora_params:,}\")\n",
    "        \n",
    "        hidden_size = self.base_model.config.hidden_size\n",
    "        first_device = next(self.base_model.parameters()).device\n",
    "        model_dtype = next(self.base_model.parameters()).dtype\n",
    "        \n",
    "        self.classification_head = ClassificationHead(hidden_size, num_labels=1, dtype=model_dtype)\n",
    "        self.classification_head = self.classification_head.to(first_device)\n",
    "        \n",
    "        head_params = sum(p.numel() for p in self.classification_head.parameters())\n",
    "        trainable_params += head_params\n",
    "        total_params += head_params\n",
    "        \n",
    "        logger.info(f\"\\n Classification Head added: {head_params:,} parameters\")\n",
    "        for name, param in self.classification_head.named_parameters():\n",
    "            logger.info(f\"   {name} - Shape: {param.shape} - Params: {param.numel():,}\")\n",
    "        \n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"TS-PEFT PARAMETER STATISTICS\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"Base Model Total Parameters: {total_params - head_params:,}\")\n",
    "        logger.info(f\"Trainable LoRA Parameters: {lora_param_count:,}\")\n",
    "        logger.info(f\"Classification Head Parameters: {head_params:,}\")\n",
    "        logger.info(f\"Total Trainable Parameters: {trainable_params:,}\")\n",
    "        logger.info(f\"Total Parameters: {total_params:,}\")\n",
    "        logger.info(f\"Trainable Percentage: {100 * trainable_params / total_params:.6f}%\")\n",
    "        logger.info(f\"Total TS-PEFT Layers: {len(self.ts_peft_layers)}\")\n",
    "        logger.info(f\"{'='*80}\\n\")\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred, y_prob=None):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)\n",
    "        \n",
    "        jacc = jaccard_score(y_true, y_pred, zero_division=0)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "        npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "        \n",
    "        metrics = {\n",
    "            'cm': cm,\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp),\n",
    "            'acc': acc,\n",
    "            'bal_acc': bal_acc,\n",
    "            'prec': prec,\n",
    "            'rec': rec,\n",
    "            'f1': f1,\n",
    "            'jacc': jacc,\n",
    "            'mcc': mcc,\n",
    "            'kappa': kappa,\n",
    "            'specificity': specificity,\n",
    "            'npv': npv,\n",
    "            'fpr': fpr,\n",
    "            'fnr': fnr\n",
    "        }\n",
    "        \n",
    "        if y_prob is not None:\n",
    "            try:\n",
    "                roc_auc = roc_auc_score(y_true, y_prob)\n",
    "                pr_auc = average_precision_score(y_true, y_prob)\n",
    "                ll = log_loss(y_true, y_prob)\n",
    "                brier = brier_score_loss(y_true, y_prob)\n",
    "                \n",
    "                metrics.update({\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'log_loss': ll,\n",
    "                    'brier': brier\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not calculate probabilistic metrics: {e}\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def calculate_recall_at_k(self, embeddings, labels, k_values=[1, 3, 5, 10]):\n",
    "        results = {}\n",
    "        \n",
    "        similarity_matrix = torch.nn.functional.cosine_similarity(\n",
    "            embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2\n",
    "        )\n",
    "        \n",
    "        for k in k_values:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                query_label = labels[i]\n",
    "                similarities = similarity_matrix[i]\n",
    "                similarities[i] = -float('inf')\n",
    "                \n",
    "                if k > len(labels) - 1:\n",
    "                    k_actual = len(labels) - 1\n",
    "                else:\n",
    "                    k_actual = k\n",
    "                \n",
    "                top_k_indices = torch.topk(similarities, k_actual).indices\n",
    "                top_k_labels = [labels[idx] for idx in top_k_indices]\n",
    "                \n",
    "                if query_label in top_k_labels:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            \n",
    "            results[f'recall@{k}'] = correct / total if total > 0 else 0.0\n",
    "        \n",
    "        reciprocal_ranks = []\n",
    "        for i in range(len(labels)):\n",
    "            query_label = labels[i]\n",
    "            similarities = similarity_matrix[i]\n",
    "            similarities[i] = -float('inf')\n",
    "            \n",
    "            sorted_indices = torch.argsort(similarities, descending=True)\n",
    "            sorted_labels = [labels[idx] for idx in sorted_indices]\n",
    "            \n",
    "            try:\n",
    "                rank = sorted_labels.index(query_label) + 1\n",
    "                reciprocal_ranks.append(1.0 / rank)\n",
    "            except ValueError:\n",
    "                reciprocal_ranks.append(0.0)\n",
    "        \n",
    "        results['mrr'] = np.mean(reciprocal_ranks)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = torch.stack([torch.tensor(item['input_ids']) for item in batch])\n",
    "        attention_mask = torch.stack([torch.tensor(item['attention_mask']) for item in batch])\n",
    "        labels = torch.tensor([item['labels'] for item in batch])\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "    \n",
    "    def setup_optimizer(self, train_dataloader, num_epochs):\n",
    "        trainable_params = []\n",
    "        for layer in self.ts_peft_layers.values():\n",
    "            trainable_params.extend(layer.lora.parameters())\n",
    "        trainable_params += list(self.classification_head.parameters())\n",
    "        \n",
    "        self.optimizer = AdamW(\n",
    "            trainable_params,\n",
    "            lr=2e-4,\n",
    "            weight_decay=0.01\n",
    "        )\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        total_steps = len(train_dataloader) * num_epochs\n",
    "        warmup_steps = int(0.03 * total_steps)\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=warmup_steps,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Optimizer setup complete. Total training steps: {total_steps}\")\n",
    "        logger.info(f\"Warmup steps: {warmup_steps}\")\n",
    "    \n",
    "    def update_thresholds(self, lr: float = 1.0):\n",
    "        for layer in self.ts_peft_layers.values():\n",
    "            if hasattr(layer, '_cache_for_backward') and layer.training:\n",
    "                grad_output = torch.ones_like(\n",
    "                    layer._cache_for_backward['base_output']\n",
    "                )\n",
    "                layer.update_threshold(grad_output, lr)\n",
    "    \n",
    "    def get_sparsity_stats(self):\n",
    "        stats = {}\n",
    "        for name, layer in self.ts_peft_layers.items():\n",
    "            if hasattr(layer, '_cache_for_backward'):\n",
    "                gate = layer._cache_for_backward['gate']\n",
    "                sparsity = (1 - gate.float().mean()).item() * 100\n",
    "                stats[name] = sparsity\n",
    "        return stats\n",
    "    \n",
    "    def train_epoch(self, train_dataloader, epoch, num_epochs):\n",
    "            self.base_model.train()\n",
    "            self.classification_head.train()\n",
    "            \n",
    "            total_loss = 0\n",
    "            total_samples = 0\n",
    "            accumulation_steps = 4\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_dataloader):\n",
    "                first_device = next(self.base_model.parameters()).device\n",
    "                \n",
    "                input_ids = batch['input_ids'].to(first_device)\n",
    "                attention_mask = batch['attention_mask'].to(first_device)\n",
    "                labels = batch['labels'].to(first_device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = self.base_model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        output_hidden_states=True\n",
    "                    )\n",
    "                    \n",
    "                    hidden_states = outputs.hidden_states[-1]\n",
    "                    pooled = hidden_states.mean(dim=1)\n",
    "                    \n",
    "                    logits = self.classification_head(pooled).squeeze(-1)\n",
    "                    \n",
    "                    loss_fn = nn.BCEWithLogitsLoss()\n",
    "                    loss = loss_fn(logits, labels.float())\n",
    "                    loss = loss / accumulation_steps\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                    self.update_thresholds(lr=1.0)\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(\n",
    "                        [p for layer in self.ts_peft_layers.values() for p in layer.lora.parameters()] + \n",
    "                        list(self.classification_head.parameters()), \n",
    "                        max_norm=1.0\n",
    "                    )\n",
    "                    \n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    if self.scheduler:\n",
    "                        self.scheduler.step()\n",
    "                \n",
    "                total_loss += loss.item() * accumulation_steps\n",
    "                total_samples += input_ids.size(0)\n",
    "                \n",
    "                if batch_idx % 20 == 0:\n",
    "                    current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                    sparsity_stats = self.get_sparsity_stats()\n",
    "                    avg_sparsity = sum(sparsity_stats.values()) / len(sparsity_stats) if sparsity_stats else 0.0\n",
    "                    logger.info(\n",
    "                        f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                        f\"Batch {batch_idx}/{len(train_dataloader)} - \"\n",
    "                        f\"Loss: {(loss.item() * accumulation_steps):.4f} - \"\n",
    "                        f\"LR: {current_lr:.2e} - \"\n",
    "                        f\"Sparsity: {avg_sparsity:.2f}%\"\n",
    "                    )\n",
    "                    \n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "            \n",
    "            avg_loss = total_loss / len(train_dataloader)\n",
    "            return {'loss': avg_loss}\n",
    "    \n",
    "    def train(self):\n",
    "        train_dataset = self.train_data.map(self.preprocess, batched=False)\n",
    "        test_dataset = self.test_data.map(self.preprocess, batched=False)\n",
    "        \n",
    "        logger.info(\"\\n\" + \"=\"*80)\n",
    "        logger.info(\"APPLYING TS-PEFT CONFIGURATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        self._setup_tspeft_parameters()\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=4,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.collate_fn,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        num_epochs = 5\n",
    "        \n",
    "        self.setup_optimizer(train_dataloader, num_epochs)\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING TRAINING\")\n",
    "        logger.info(f\"Total Epochs: {num_epochs}\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        training_start = time.time()\n",
    "        \n",
    "        process = psutil.Process(os.getpid())\n",
    "        mem_before = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            logger.info(f\"\\n{'='*60}\")\n",
    "            logger.info(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            logger.info(f\"{'='*60}\")\n",
    "            \n",
    "            train_metrics = self.train_epoch(train_dataloader, epoch, num_epochs)\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            self.training_stats['epoch_times'].append(epoch_time)\n",
    "            self.training_stats['epoch_losses'].append(train_metrics['loss'])\n",
    "            \n",
    "            logger.info(f\"Epoch {epoch+1} completed in {epoch_time:.2f}s\")\n",
    "            logger.info(f\"Training Loss: {train_metrics['loss']:.4f}\")\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        \n",
    "        total_training_time = time.time() - training_start\n",
    "        \n",
    "        mem_after = process.memory_info().rss / 1024 / 1024\n",
    "        mem_used = mem_after - mem_before\n",
    "        \n",
    "        logger.info(f\"\\n{'='*80}\")\n",
    "        logger.info(\"TRAINING COMPLETE\")\n",
    "        logger.info(f\"{'='*80}\")\n",
    "        logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "        logger.info(f\"Average Epoch Time: {np.mean(self.training_stats['epoch_times']):.2f}s\")\n",
    "        logger.info(f\"Final Training Loss: {self.training_stats['epoch_losses'][-1]:.4f}\")\n",
    "        logger.info(f\"Memory Usage: {mem_used:.1f} MB\")\n",
    "        logger.info(f\"{'='*80}\\n\")\n",
    "        \n",
    "        self.print_model_distribution()\n",
    "        \n",
    "        os.makedirs(\"codeqwen1.5-tspeft-clone\", exist_ok=True)\n",
    "        self.base_model.save_pretrained(\"codeqwen1.5-tspeft-clone\")\n",
    "        torch.save(self.classification_head.state_dict(), \"codeqwen1.5-tspeft-clone/classification_head.pt\")\n",
    "        logger.info(\"Models saved successfully to codeqwen1.5-tspeft-clone/\")\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return self.base_model, total_training_time\n",
    "    \n",
    "    def evaluate_comprehensive(self, model, test_dataset):\n",
    "        model.eval()\n",
    "        self.classification_head.eval()\n",
    "        \n",
    "        logger.info(\"=\"*80)\n",
    "        logger.info(\"STARTING COMPREHENSIVE EVALUATION\")\n",
    "        logger.info(\"=\"*80)\n",
    "        \n",
    "        test_df = pd.read_csv(self.test_file)\n",
    "        test_labels = test_df[self.label_col].tolist()\n",
    "        \n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_embeddings = []\n",
    "        \n",
    "        inference_start = time.time()\n",
    "        total_samples = len(test_dataset)\n",
    "        \n",
    "        logger.info(f\"Processing {total_samples} test samples...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx in range(len(test_dataset)):\n",
    "                sample = test_dataset[idx]\n",
    "                \n",
    "                input_ids = torch.tensor([sample['input_ids']])\n",
    "                attention_mask = torch.tensor([sample['attention_mask']])\n",
    "                \n",
    "                first_device = next(model.parameters()).device\n",
    "                input_ids = input_ids.to(first_device)\n",
    "                attention_mask = attention_mask.to(first_device)\n",
    "                \n",
    "                outputs = model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    output_hidden_states=True\n",
    "                )\n",
    "                \n",
    "                hidden_states = outputs.hidden_states[-1]\n",
    "                pooled = hidden_states.mean(dim=1)\n",
    "                \n",
    "                all_embeddings.append(pooled.squeeze().cpu())\n",
    "                \n",
    "                logits = self.classification_head(pooled).squeeze(-1)\n",
    "                \n",
    "                prob = torch.sigmoid(logits).item()\n",
    "                pred = 1 if prob > 0.5 else 0\n",
    "                \n",
    "                all_preds.append(pred)\n",
    "                all_probs.append(prob)\n",
    "                \n",
    "                if (idx + 1) % 100 == 0:\n",
    "                    logger.info(f\"Processed {idx + 1}/{total_samples} samples\")\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        inference_time = time.time() - inference_start\n",
    "        samples_per_sec = total_samples / inference_time\n",
    "        \n",
    "        logger.info(f\"Inference completed in {inference_time:.2f}s\")\n",
    "        logger.info(f\"Throughput: {samples_per_sec:.2f} samples/sec\")\n",
    "        \n",
    "        metrics = self.calculate_metrics(test_labels, all_preds, all_probs)\n",
    "        \n",
    "        all_embeddings = torch.stack(all_embeddings)\n",
    "        recall_metrics = self.calculate_recall_at_k(all_embeddings, test_labels)\n",
    "        metrics.update(recall_metrics)\n",
    "        \n",
    "        metrics['inference_time'] = inference_time\n",
    "        metrics['samples_per_sec'] = samples_per_sec\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "def print_results(metrics, dataset_name):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS: {dataset_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{metrics['cm']}\")\n",
    "    print(f\"\\nTrue Negatives (TN): {metrics['tn']}\")\n",
    "    print(f\"False Positives (FP): {metrics['fp']}\")\n",
    "    print(f\"False Negatives (FN): {metrics['fn']}\")\n",
    "    print(f\"True Positives (TP): {metrics['tp']}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CLASSIFICATION METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Accuracy: {metrics['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {metrics['bal_acc']:.4f}\")\n",
    "    print(f\"Precision: {metrics['prec']:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): {metrics['rec']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"Specificity: {metrics['specificity']:.4f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {metrics['npv']:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {metrics['fpr']:.4f}\")\n",
    "    print(f\"False Negative Rate (FNR): {metrics['fnr']:.4f}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ADVANCED METRICS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Jaccard Score: {metrics['jacc']:.4f}\")\n",
    "    print(f\"Matthews Correlation Coefficient (MCC): {metrics['mcc']:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
    "    \n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PROBABILISTIC METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "    if 'pr_auc' in metrics:\n",
    "        print(f\"Precision-Recall AUC: {metrics['pr_auc']:.4f}\")\n",
    "    if 'log_loss' in metrics:\n",
    "        print(f\"Log Loss: {metrics['log_loss']:.4f}\")\n",
    "    if 'brier' in metrics:\n",
    "        print(f\"Brier Score: {metrics['brier']:.4f}\")\n",
    "    \n",
    "    if 'recall@1' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"RETRIEVAL METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Recall@1: {metrics['recall@1']:.4f}\")\n",
    "        print(f\"Recall@3: {metrics['recall@3']:.4f}\")\n",
    "        print(f\"Recall@5: {metrics['recall@5']:.4f}\")\n",
    "        print(f\"Recall@10: {metrics['recall@10']:.4f}\")\n",
    "        print(f\"Mean Reciprocal Rank (MRR): {metrics['mrr']:.4f}\")\n",
    "    \n",
    "    if 'inference_time' in metrics:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"PERFORMANCE METRICS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Inference Time: {metrics['inference_time']:.2f}s\")\n",
    "        print(f\"Throughput: {metrics['samples_per_sec']:.2f} samples/sec\")\n",
    "    \n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def run_tspeft_experiment(train_file, test_file, func1_col, func2_col, label_col, cache_dir=None, \n",
    "                          rank=32, alpha=0.5, dropout=0.05, s=4e-5, lambda_reg=4.5e-5):\n",
    "    logger.info(\"=\"*80)\n",
    "    logger.info(\"CODE CLONE DETECTION WITH TS-PEFT\")\n",
    "    logger.info(\"=\"*80)\n",
    "    \n",
    "    tspeft_trainer = TSPEFTCloneTrainer(\n",
    "        train_file, \n",
    "        test_file, \n",
    "        func1_col, \n",
    "        func2_col, \n",
    "        label_col,\n",
    "        cache_dir=cache_dir,\n",
    "        rank=rank,\n",
    "        alpha=alpha,\n",
    "        dropout=dropout,\n",
    "        s=s,\n",
    "        lambda_reg=lambda_reg\n",
    "    )\n",
    "    \n",
    "    model, training_time = tspeft_trainer.train()\n",
    "    \n",
    "    logger.info(f\"\\n{'='*80}\")\n",
    "    logger.info(\"FINAL TEST EVALUATION\")\n",
    "    logger.info(f\"{'='*80}\")\n",
    "    \n",
    "    test_dataset = tspeft_trainer.test_data.map(tspeft_trainer.preprocess, batched=False)\n",
    "    metrics = tspeft_trainer.evaluate_comprehensive(model, test_dataset)\n",
    "    \n",
    "    print_results(metrics, \"TEST SET\")\n",
    "    \n",
    "    return tspeft_trainer, model, metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_file = '/train.csv'\n",
    "    test_file = '/test.csv'\n",
    "    func1_col = \"func1\"\n",
    "    func2_col = \"func2\"\n",
    "    label_col = \"label\"\n",
    "    cache_dir = '/hf_cache'\n",
    "    \n",
    "    try:\n",
    "        tspeft_trainer, model, results = run_tspeft_experiment(\n",
    "            train_file, \n",
    "            test_file, \n",
    "            func1_col, \n",
    "            func2_col, \n",
    "            label_col,\n",
    "            cache_dir=cache_dir,\n",
    "            rank=32,\n",
    "            alpha=0.5,\n",
    "            dropout=0.05,\n",
    "            s=4e-5,\n",
    "            lambda_reg=4.5e-5\n",
    "        )\n",
    "        logger.info(\"TS-PEFT experiment completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
